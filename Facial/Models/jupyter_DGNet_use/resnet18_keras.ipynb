{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## First Part: Load the data: \n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "def shuffle(x_,y_):\n",
    "    s = np.arange(x_.shape[0])\n",
    "    s = np.random.shuffle(s)\n",
    "\n",
    "    x_re = x_[s]\n",
    "    y_re = y_[s]\n",
    "\n",
    "    x_re = np.reshape(x_re,(len(x_),48,48))\n",
    "    y_re = np.reshape(y_re,(len(y_)))\n",
    "    return x_re,y_re\n",
    "\n",
    "def read_fer(path):\n",
    "    # train_path = \"C:\\\\Users\\\\Jiaming Nie\\\\Documents\\\\Work-DeepGlint\\Facial\\datasets\\\\train.csv\"\n",
    "    data = pd.read_csv(path, dtype='a')\n",
    "    label = np.array(data['emotion'])\n",
    "    img_data = np.array(data['pixels'])\n",
    "\n",
    "    N_sample = label.size\n",
    "\n",
    "    x_data = np.zeros((N_sample, 48 * 48))\n",
    "    # train_label = np.zeros((N_sample, 7), dtype=int)\n",
    "    y_label = np.zeros(N_sample, dtype=int)\n",
    "    # print(train_label)\n",
    "\n",
    "    for i in range(N_sample):\n",
    "        x = img_data[i]\n",
    "        x = np.fromstring(x, dtype=float, sep=' ')\n",
    "        x_max = x.max()\n",
    "        x = x / (x_max + 0.0001)\n",
    "        # print x_max\n",
    "        # print x\n",
    "        x_data[i] = x\n",
    "        y_label[i] = int(label[i])\n",
    "        # train_label[i, label[i]] = 1 #This step seems direct one-hot encoding\n",
    "        # print(y_label[i])\n",
    "        #    img_x = np.reshape(x, (48, 48))\n",
    "        #    plt.subplot(10,10,i+1)\n",
    "        #    plt.axis('off')\n",
    "        #    plt.imshow(img_x, plt.cm.gray)\n",
    "\n",
    "    x_data = np.reshape(x_data,(len(x_data),48,48))\n",
    "    return x_data, y_label\n",
    "\n",
    "def ReadData_fer():\n",
    "    # ubuntu path\n",
    "    #path_train = \"/home/jiaming/code/DeepGlint-Work/Facial/datasets/train.csv\"\n",
    "    #path_test = \"/home/jiaming/code/DeepGlint-Work/Facial/datasets/test.csv\"\n",
    "\n",
    "    # windows path\n",
    "    path_train = \"/train/trainset/1/train.csv\"\n",
    "    path_test = \"/train/trainset/1/test.csv\"\n",
    "    path_vali = \"/train/trainset/1/val.csv\"\n",
    "    \n",
    "    x_train, y_train = read_fer(path_train)\n",
    "    x_test, y_test = read_fer(path_test)\n",
    "    x_vali, y_vali = read_fer(path_vali)\n",
    "\n",
    "    x_train, y_train = shuffle(x_train, y_train)\n",
    "    x_test, y_test = shuffle(x_test, y_test)\n",
    "    x_vali, y_vali = shuffle(x_vali, y_vali)\n",
    "\n",
    "    return x_train,y_train,x_test,y_test,x_vali,y_vali\n",
    "\n",
    "def zca_whitening(X):\n",
    "    \"\"\"\n",
    "        Function to compute ZCA whitening matrix (aka Mahalanobis whitening).\n",
    "        INPUT:  X: [M x N] matrix.\n",
    "            Rows: Variables\n",
    "            Columns: Observations\n",
    "        OUTPUT: ZCAMatrix: [M x M] matrix\n",
    "        \"\"\"\n",
    "    mean_ = np.mean(X)\n",
    "    X = X - mean_\n",
    "    # Covariance matrix [column-wise variables]: Sigma = (X-mu)' * (X-mu) / N\n",
    "    sigma = np.cov(X, rowvar=True)  # [M x M]\n",
    "    # Singular Value Decomposition. X = U * np.diag(S) * V\n",
    "    U, S, V = np.linalg.svd(sigma)\n",
    "    # U: [M x M] eigenvectors of sigma.\n",
    "    # S: [M x 1] eigenvalues of sigma.\n",
    "    # V: [M x M] transpose of U\n",
    "    # Whitening constant: prevents division by zero\n",
    "    epsilon = 0.1\n",
    "    # ZCA Whitening matrix: U * Lambda * U'\n",
    "    ZCAMatrix = np.dot(U, np.dot(np.diag(1.0 / np.sqrt(S + epsilon)), U.T))  # [M x M]\n",
    "    return ZCAMatrix\n",
    "\n",
    "def normalization(x_):\n",
    "\n",
    "    length = len(x_)\n",
    "\n",
    "    for i in range(length):\n",
    "        x_[i] = zca_whitening(x_[i])\n",
    "\n",
    "    return x_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28709, 48, 48, 1)\n",
      "(3589, 48, 48, 1)\n"
     ]
    }
   ],
   "source": [
    "x_train,y_train,x_test,y_test,x_vali,y_vali = ReadData_fer()\n",
    "\n",
    "# Normalization\n",
    "#x_train = normalization(x_train)\n",
    "#x_test = normalization(x_test)\n",
    "#x_vali = normalization(x_vali)\n",
    "\n",
    "x_train = x_train.reshape((len(x_train), 48, 48, 1))\n",
    "x_test = x_test.reshape((len(x_test), 48, 48, 1))\n",
    "x_vali = x_vali.reshape((len(x_vali),48,48,1))\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding=utf-8, keras model implementation \n",
    "\n",
    "from __future__ import division\n",
    "\n",
    "import six\n",
    "from keras.models import Model\n",
    "from keras.layers import (\n",
    "    Input,\n",
    "    Activation,\n",
    "    Dense,\n",
    "    Flatten\n",
    ")\n",
    "from keras.layers.convolutional import (\n",
    "    Conv2D,\n",
    "    MaxPooling2D,\n",
    "    AveragePooling2D\n",
    ")\n",
    "from keras.layers.merge import add\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.regularizers import l2\n",
    "\n",
    "import tensorflow as tf  \n",
    "import keras.backend.tensorflow_backend as KTF  \n",
    "KTF.set_session(tf.Session(config=tf.ConfigProto(device_count={'gpu':0})))  \n",
    "\n",
    "# import tensorflow as tf\n",
    "# gpu_options = tf.GPUOptions(allow_growth=True)\n",
    "# sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))\n",
    "\n",
    "# # 設定 Keras 使用的 Session\n",
    "# tf.keras.backend.set_session(sess)\n",
    "\n",
    "# #THEANO_FLAGS=device=gpu, floatX=32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def _bn_relu(input):\n",
    "    \"\"\"Helper to build a BN -> relu block\n",
    "    \"\"\"\n",
    "    norm = BatchNormalization(axis=CHANNEL_AXIS)(input)\n",
    "    return Activation(\"relu\")(norm)\n",
    "\n",
    "\n",
    "def _conv_bn_relu(**conv_params):\n",
    "    \"\"\"Helper to build a conv -> BN -> relu block\n",
    "    \"\"\"\n",
    "    filters = conv_params[\"filters\"]\n",
    "    kernel_size = conv_params[\"kernel_size\"]\n",
    "    strides = conv_params.setdefault(\"strides\", (1, 1))\n",
    "    kernel_initializer = conv_params.setdefault(\"kernel_initializer\", \"glorot_uniform\")\n",
    "    padding = conv_params.setdefault(\"padding\", \"same\")\n",
    "    kernel_regularizer = conv_params.setdefault(\"kernel_regularizer\", l2(1.e-5))\n",
    "\n",
    "    def f(input):\n",
    "        conv = Conv2D(filters=filters, kernel_size=kernel_size,\n",
    "                      strides=strides, padding=padding,\n",
    "                      kernel_initializer=kernel_initializer,\n",
    "                      kernel_regularizer=kernel_regularizer)(input)\n",
    "        return _bn_relu(conv)\n",
    "\n",
    "    return f\n",
    "\n",
    "\n",
    "def _bn_relu_conv(**conv_params):\n",
    "    \"\"\"Helper to build a BN -> relu -> conv block.\n",
    "    This is an improved scheme proposed in http://arxiv.org/pdf/1603.05027v2.pdf\n",
    "    \"\"\"\n",
    "    filters = conv_params[\"filters\"]\n",
    "    kernel_size = conv_params[\"kernel_size\"]\n",
    "    strides = conv_params.setdefault(\"strides\", (1, 1))\n",
    "    kernel_initializer = conv_params.setdefault(\"kernel_initializer\", \"glorot_uniform\")\n",
    "    padding = conv_params.setdefault(\"padding\", \"same\")\n",
    "    kernel_regularizer = conv_params.setdefault(\"kernel_regularizer\", l2(1.e-5))\n",
    "\n",
    "    def f(input):\n",
    "        activation = _bn_relu(input)\n",
    "        return Conv2D(filters=filters, kernel_size=kernel_size,\n",
    "                      strides=strides, padding=padding,\n",
    "                      kernel_initializer=kernel_initializer,\n",
    "                      kernel_regularizer=kernel_regularizer)(activation)\n",
    "\n",
    "    return f\n",
    "\n",
    "\n",
    "def _shortcut(input, residual):\n",
    "    \"\"\"Adds a shortcut between input and residual block and merges them with \"sum\"\n",
    "    \"\"\"\n",
    "    # Expand channels of shortcut to match residual.\n",
    "    # Stride appropriately to match residual (width, height)\n",
    "    # Should be int if network architecture is correctly configured.\n",
    "    input_shape = K.int_shape(input)\n",
    "    residual_shape = K.int_shape(residual)\n",
    "    stride_width = int(round(input_shape[ROW_AXIS] / residual_shape[ROW_AXIS]))\n",
    "    stride_height = int(round(input_shape[COL_AXIS] / residual_shape[COL_AXIS]))\n",
    "    equal_channels = input_shape[CHANNEL_AXIS] == residual_shape[CHANNEL_AXIS]\n",
    "\n",
    "    shortcut = input\n",
    "    # 1 X 1 conv if shape is different. Else identity.\n",
    "    if stride_width > 1 or stride_height > 1 or not equal_channels:\n",
    "        shortcut = Conv2D(filters=residual_shape[CHANNEL_AXIS],\n",
    "                          kernel_size=(1, 1),\n",
    "                          strides=(stride_width, stride_height),\n",
    "                          padding=\"valid\",\n",
    "                          kernel_initializer=\"he_normal\",\n",
    "                          kernel_regularizer=l2(0.0001))(input)\n",
    "\n",
    "    return add([shortcut, residual])\n",
    "\n",
    "\n",
    "def _residual_block(block_function, filters, repetitions, is_first_layer=False):\n",
    "    \"\"\"Builds a residual block with repeating bottleneck blocks.\n",
    "    \"\"\"\n",
    "    def f(input):\n",
    "        for i in range(repetitions):\n",
    "            init_strides = (1, 1)\n",
    "            if i == 0 and not is_first_layer:\n",
    "                init_strides = (2, 2)\n",
    "            input = block_function(filters=filters, init_strides=init_strides,\n",
    "                                   is_first_block_of_first_layer=(is_first_layer and i == 0))(input)\n",
    "        return input\n",
    "\n",
    "    return f\n",
    "\n",
    "\n",
    "def basic_block(filters, init_strides=(1, 1), is_first_block_of_first_layer=False):\n",
    "    \"\"\"Basic 3 X 3 convolution blocks for use on resnets with layers <= 34.\n",
    "    Follows improved proposed scheme in http://arxiv.org/pdf/1603.05027v2.pdf\n",
    "    \"\"\"\n",
    "    def f(input):\n",
    "\n",
    "        if is_first_block_of_first_layer:\n",
    "            # don't repeat bn->relu since we just did bn->relu->maxpool\n",
    "            conv1 = Conv2D(filters=filters, kernel_size=(3, 3),\n",
    "                           strides=init_strides,\n",
    "                           padding=\"same\",\n",
    "                           kernel_regularizer=l2(1e-5))(input)\n",
    "        else:\n",
    "            conv1 = _bn_relu_conv(filters=filters, kernel_size=(3, 3),\n",
    "                                  strides=init_strides)(input)\n",
    "\n",
    "        residual = _bn_relu_conv(filters=filters, kernel_size=(3, 3))(conv1)\n",
    "        return _shortcut(input, residual)\n",
    "\n",
    "    return f\n",
    "\n",
    "\n",
    "def bottleneck(filters, init_strides=(1, 1), is_first_block_of_first_layer=False):\n",
    "    \"\"\"Bottleneck architecture for > 34 layer resnet.\n",
    "    Follows improved proposed scheme in http://arxiv.org/pdf/1603.05027v2.pdf\n",
    "    Returns:\n",
    "        A final conv layer of filters * 4\n",
    "    \"\"\"\n",
    "    def f(input):\n",
    "\n",
    "        if is_first_block_of_first_layer:\n",
    "            # don't repeat bn->relu since we just did bn->relu->maxpool\n",
    "            conv_1_1 = Conv2D(filters=filters, kernel_size=(1, 1),\n",
    "                              strides=init_strides,\n",
    "                              padding=\"same\",\n",
    "                              kernel_initializer=\"glorot_uniform\",\n",
    "                              kernel_regularizer=l2(1e-5))(input)\n",
    "        else:\n",
    "            conv_1_1 = _bn_relu_conv(filters=filters, kernel_size=(1, 1),\n",
    "                                     strides=init_strides)(input)\n",
    "\n",
    "        conv_3_3 = _bn_relu_conv(filters=filters, kernel_size=(3, 3))(conv_1_1)\n",
    "        residual = _bn_relu_conv(filters=filters * 4, kernel_size=(1, 1))(conv_3_3)\n",
    "        return _shortcut(input, residual)\n",
    "\n",
    "    return f\n",
    "\n",
    "\n",
    "def _handle_dim_ordering():\n",
    "    global ROW_AXIS\n",
    "    global COL_AXIS\n",
    "    global CHANNEL_AXIS\n",
    "    if K.image_dim_ordering() == 'tf':\n",
    "        ROW_AXIS = 1\n",
    "        COL_AXIS = 2\n",
    "        CHANNEL_AXIS = 3\n",
    "    else:\n",
    "        CHANNEL_AXIS = 1\n",
    "        ROW_AXIS = 2\n",
    "        COL_AXIS = 3\n",
    "\n",
    "\n",
    "def _get_block(identifier):\n",
    "    if isinstance(identifier, six.string_types):\n",
    "        res = globals().get(identifier)\n",
    "        if not res:\n",
    "            raise ValueError('Invalid {}'.format(identifier))\n",
    "        return res\n",
    "    return identifier\n",
    "\n",
    "\n",
    "class ResnetBuilder(object):\n",
    "    @staticmethod\n",
    "    def build(input_shape, num_outputs, block_fn, repetitions):\n",
    "        \"\"\"Builds a custom ResNet like architecture.\n",
    "        Args:\n",
    "            input_shape: The input shape in the form (nb_channels, nb_rows, nb_cols)\n",
    "            num_outputs: The number of outputs at final softmax layer\n",
    "            block_fn: The block function to use. This is either `basic_block` or `bottleneck`.\n",
    "                The original paper used basic_block for layers < 50\n",
    "            repetitions: Number of repetitions of various block units.\n",
    "                At each block unit, the number of filters are doubled and the input size is halved\n",
    "        Returns:\n",
    "            The keras `Model`.\n",
    "        \"\"\"\n",
    "        _handle_dim_ordering()\n",
    "        if len(input_shape) != 3:\n",
    "            raise Exception(\"Input shape should be a tuple (nb_channels, nb_rows, nb_cols)\")\n",
    "\n",
    "        # Permute dimension order if necessary\n",
    "        if K.image_dim_ordering() == 'tf':\n",
    "            input_shape = (input_shape[1], input_shape[2], input_shape[0])\n",
    "\n",
    "        # Load function from str if needed.\n",
    "        block_fn = _get_block(block_fn)\n",
    "\n",
    "        input = Input(shape=input_shape)\n",
    "        conv1 = _conv_bn_relu(filters=64, kernel_size=(7, 7), strides=(2, 2))(input)\n",
    "        pool1 = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding=\"same\")(conv1)\n",
    "\n",
    "        block = pool1\n",
    "        filters = 64\n",
    "        for i, r in enumerate(repetitions):\n",
    "            block = _residual_block(block_fn, filters=filters, repetitions=r, is_first_layer=(i == 0))(block)\n",
    "            filters *= 2\n",
    "\n",
    "        # Last activation\n",
    "        block = _bn_relu(block)\n",
    "\n",
    "        # Classifier block\n",
    "        block_shape = K.int_shape(block)\n",
    "        pool2 = AveragePooling2D(pool_size=(block_shape[ROW_AXIS], block_shape[COL_AXIS]),\n",
    "                                 strides=(1, 1))(block)\n",
    "        flatten1 = Flatten()(pool2)\n",
    "        dense = Dense(units=num_outputs, kernel_initializer=\"he_normal\",\n",
    "                      activation=\"softmax\")(flatten1)\n",
    "\n",
    "        model = Model(inputs=input, outputs=dense)\n",
    "        return model\n",
    "\n",
    "    @staticmethod\n",
    "    def build_resnet_18(input_shape, num_outputs):\n",
    "        return ResnetBuilder.build(input_shape, num_outputs, basic_block, [2, 2, 2, 2])\n",
    "\n",
    "    @staticmethod\n",
    "    def build_resnet_34(input_shape, num_outputs):\n",
    "        return ResnetBuilder.build(input_shape, num_outputs, basic_block, [3, 4, 6, 3])\n",
    "\n",
    "    @staticmethod\n",
    "    def build_resnet_50(input_shape, num_outputs):\n",
    "        return ResnetBuilder.build(input_shape, num_outputs, bottleneck, [3, 4, 6, 3])\n",
    "\n",
    "    @staticmethod\n",
    "    def build_resnet_101(input_shape, num_outputs):\n",
    "        return ResnetBuilder.build(input_shape, num_outputs, bottleneck, [3, 4, 23, 3])\n",
    "\n",
    "    @staticmethod\n",
    "    def build_resnet_152(input_shape, num_outputs):\n",
    "        return ResnetBuilder.build(input_shape, num_outputs, bottleneck, [3, 8, 36, 3])\n",
    "\n",
    "\n",
    "from keras import backend as K\n",
    "import numpy as np\n",
    "from keras.utils import to_categorical\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.metrics import top_k_categorical_accuracy\n",
    "from keras.optimizers import *\n",
    "\n",
    "\n",
    "DIM_ORDERING = {'th', 'tf'}\n",
    "\n",
    "\n",
    "def _test_model_compile(model):\n",
    "    for ordering in DIM_ORDERING:\n",
    "        K.set_image_dim_ordering(ordering)\n",
    "        model.compile(loss=\"categorical_crossentropy\", optimizer=\"sgd\")\n",
    "        assert True, \"Failed to compile with '{}' dim ordering\".format(ordering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_1 (InputLayer)             (None, 48, 48, 1)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)                (None, 24, 24, 64)    3200        input_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNorm (None, 24, 24, 64)    256         conv2d_1[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "activation_1 (Activation)        (None, 24, 24, 64)    0           batch_normalization_1[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)   (None, 12, 12, 64)    0           activation_1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)                (None, 12, 12, 64)    36928       max_pooling2d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNorm (None, 12, 12, 64)    256         conv2d_2[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "activation_2 (Activation)        (None, 12, 12, 64)    0           batch_normalization_2[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)                (None, 12, 12, 64)    36928       activation_2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "add_1 (Add)                      (None, 12, 12, 64)    0           max_pooling2d_1[0][0]            \n",
      "                                                                   conv2d_3[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNorm (None, 12, 12, 64)    256         add_1[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "activation_3 (Activation)        (None, 12, 12, 64)    0           batch_normalization_3[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)                (None, 12, 12, 64)    36928       activation_3[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNorm (None, 12, 12, 64)    256         conv2d_4[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "activation_4 (Activation)        (None, 12, 12, 64)    0           batch_normalization_4[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)                (None, 12, 12, 64)    36928       activation_4[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "add_2 (Add)                      (None, 12, 12, 64)    0           add_1[0][0]                      \n",
      "                                                                   conv2d_5[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNorm (None, 12, 12, 64)    256         add_2[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "activation_5 (Activation)        (None, 12, 12, 64)    0           batch_normalization_5[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)                (None, 6, 6, 128)     73856       activation_5[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNorm (None, 6, 6, 128)     512         conv2d_6[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "activation_6 (Activation)        (None, 6, 6, 128)     0           batch_normalization_6[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)                (None, 6, 6, 128)     8320        add_2[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)                (None, 6, 6, 128)     147584      activation_6[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "add_3 (Add)                      (None, 6, 6, 128)     0           conv2d_8[0][0]                   \n",
      "                                                                   conv2d_7[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNorm (None, 6, 6, 128)     512         add_3[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "activation_7 (Activation)        (None, 6, 6, 128)     0           batch_normalization_7[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)                (None, 6, 6, 128)     147584      activation_7[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNorm (None, 6, 6, 128)     512         conv2d_9[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "activation_8 (Activation)        (None, 6, 6, 128)     0           batch_normalization_8[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)               (None, 6, 6, 128)     147584      activation_8[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "add_4 (Add)                      (None, 6, 6, 128)     0           add_3[0][0]                      \n",
      "                                                                   conv2d_10[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNorm (None, 6, 6, 128)     512         add_4[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "activation_9 (Activation)        (None, 6, 6, 128)     0           batch_normalization_9[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)               (None, 3, 3, 256)     295168      activation_9[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNor (None, 3, 3, 256)     1024        conv2d_11[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_10 (Activation)       (None, 3, 3, 256)     0           batch_normalization_10[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)               (None, 3, 3, 256)     33024       add_4[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)               (None, 3, 3, 256)     590080      activation_10[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "add_5 (Add)                      (None, 3, 3, 256)     0           conv2d_13[0][0]                  \n",
      "                                                                   conv2d_12[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNor (None, 3, 3, 256)     1024        add_5[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "activation_11 (Activation)       (None, 3, 3, 256)     0           batch_normalization_11[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)               (None, 3, 3, 256)     590080      activation_11[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNor (None, 3, 3, 256)     1024        conv2d_14[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_12 (Activation)       (None, 3, 3, 256)     0           batch_normalization_12[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)               (None, 3, 3, 256)     590080      activation_12[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "add_6 (Add)                      (None, 3, 3, 256)     0           add_5[0][0]                      \n",
      "                                                                   conv2d_15[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNor (None, 3, 3, 256)     1024        add_6[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "activation_13 (Activation)       (None, 3, 3, 256)     0           batch_normalization_13[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)               (None, 2, 2, 512)     1180160     activation_13[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNor (None, 2, 2, 512)     2048        conv2d_16[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_14 (Activation)       (None, 2, 2, 512)     0           batch_normalization_14[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)               (None, 2, 2, 512)     131584      add_6[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)               (None, 2, 2, 512)     2359808     activation_14[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "add_7 (Add)                      (None, 2, 2, 512)     0           conv2d_18[0][0]                  \n",
      "                                                                   conv2d_17[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNor (None, 2, 2, 512)     2048        add_7[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "activation_15 (Activation)       (None, 2, 2, 512)     0           batch_normalization_15[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)               (None, 2, 2, 512)     2359808     activation_15[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNor (None, 2, 2, 512)     2048        conv2d_19[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_16 (Activation)       (None, 2, 2, 512)     0           batch_normalization_16[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)               (None, 2, 2, 512)     2359808     activation_16[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "add_8 (Add)                      (None, 2, 2, 512)     0           add_7[0][0]                      \n",
      "                                                                   conv2d_20[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNor (None, 2, 2, 512)     2048        add_8[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "activation_17 (Activation)       (None, 2, 2, 512)     0           batch_normalization_17[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePool (None, 1, 1, 512)     0           activation_17[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)              (None, 512)           0           average_pooling2d_1[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 7)             3591        flatten_1[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 11,184,647\n",
      "Trainable params: 11,176,839\n",
      "Non-trainable params: 7,808\n",
      "____________________________________________________________________________________________________\n",
      "--Non Training--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Train loss:', 2.2075868106161591)\n",
      "('Train accuracy:', 0.015430701173847922)\n",
      "Train on 28709 samples, validate on 3589 samples\n",
      "Epoch 1/20\n",
      "28709/28709 [==============================] - 17s - loss: 2.0157 - acc: 0.3444 - top_k_categorical_accuracy: 0.9189 - val_loss: 3.6284 - val_acc: 0.2162 - val_top_k_categorical_accuracy: 0.9114\n",
      "Epoch 2/20\n",
      "28709/28709 [==============================] - 12s - loss: 1.9123 - acc: 0.3946 - top_k_categorical_accuracy: 0.9408 - val_loss: 1.9155 - val_acc: 0.4126 - val_top_k_categorical_accuracy: 0.9401\n",
      "Epoch 3/20\n",
      "28709/28709 [==============================] - 12s - loss: 1.8744 - acc: 0.4147 - top_k_categorical_accuracy: 0.9451 - val_loss: 1.8790 - val_acc: 0.4160 - val_top_k_categorical_accuracy: 0.9454\n",
      "Epoch 4/20\n",
      "28709/28709 [==============================] - 12s - loss: 1.8534 - acc: 0.4209 - top_k_categorical_accuracy: 0.9480 - val_loss: 1.8702 - val_acc: 0.4154 - val_top_k_categorical_accuracy: 0.9479\n",
      "Epoch 5/20\n",
      "28709/28709 [==============================] - 12s - loss: 1.8377 - acc: 0.4333 - top_k_categorical_accuracy: 0.9497 - val_loss: 1.8605 - val_acc: 0.4221 - val_top_k_categorical_accuracy: 0.9518\n",
      "Epoch 6/20\n",
      "28709/28709 [==============================] - 12s - loss: 1.8267 - acc: 0.4340 - top_k_categorical_accuracy: 0.9517 - val_loss: 1.8511 - val_acc: 0.4269 - val_top_k_categorical_accuracy: 0.9512\n",
      "Epoch 7/20\n",
      "28709/28709 [==============================] - 12s - loss: 1.8176 - acc: 0.4382 - top_k_categorical_accuracy: 0.9513 - val_loss: 1.8431 - val_acc: 0.4291 - val_top_k_categorical_accuracy: 0.9535\n",
      "Epoch 8/20\n",
      "28709/28709 [==============================] - 12s - loss: 1.8065 - acc: 0.4445 - top_k_categorical_accuracy: 0.9530 - val_loss: 1.8388 - val_acc: 0.4322 - val_top_k_categorical_accuracy: 0.9540\n",
      "Epoch 9/20\n",
      "28709/28709 [==============================] - 12s - loss: 1.7990 - acc: 0.4469 - top_k_categorical_accuracy: 0.9540 - val_loss: 1.8345 - val_acc: 0.4355 - val_top_k_categorical_accuracy: 0.9529\n",
      "Epoch 10/20\n",
      "28709/28709 [==============================] - 12s - loss: 1.7930 - acc: 0.4485 - top_k_categorical_accuracy: 0.9544 - val_loss: 1.8307 - val_acc: 0.4391 - val_top_k_categorical_accuracy: 0.9537\n",
      "Epoch 11/20\n",
      "28709/28709 [==============================] - 12s - loss: 1.7854 - acc: 0.4528 - top_k_categorical_accuracy: 0.9548 - val_loss: 1.8290 - val_acc: 0.4383 - val_top_k_categorical_accuracy: 0.9532\n",
      "Epoch 12/20\n",
      "28709/28709 [==============================] - 12s - loss: 1.7807 - acc: 0.4550 - top_k_categorical_accuracy: 0.9550 - val_loss: 1.8217 - val_acc: 0.4377 - val_top_k_categorical_accuracy: 0.9535\n",
      "Epoch 13/20\n",
      "28709/28709 [==============================] - 12s - loss: 1.7745 - acc: 0.4572 - top_k_categorical_accuracy: 0.9556 - val_loss: 1.8178 - val_acc: 0.4413 - val_top_k_categorical_accuracy: 0.9535\n",
      "Epoch 14/20\n",
      "28709/28709 [==============================] - 12s - loss: 1.7689 - acc: 0.4598 - top_k_categorical_accuracy: 0.9565 - val_loss: 1.8153 - val_acc: 0.4400 - val_top_k_categorical_accuracy: 0.9537\n",
      "Epoch 15/20\n",
      "28709/28709 [==============================] - 12s - loss: 1.7646 - acc: 0.4624 - top_k_categorical_accuracy: 0.9565 - val_loss: 1.8125 - val_acc: 0.4419 - val_top_k_categorical_accuracy: 0.9543\n",
      "Epoch 16/20\n",
      "28709/28709 [==============================] - 12s - loss: 1.7586 - acc: 0.4642 - top_k_categorical_accuracy: 0.9559 - val_loss: 1.8104 - val_acc: 0.4455 - val_top_k_categorical_accuracy: 0.9535\n",
      "Epoch 17/20\n",
      "28709/28709 [==============================] - 12s - loss: 1.7558 - acc: 0.4653 - top_k_categorical_accuracy: 0.9568 - val_loss: 1.8062 - val_acc: 0.4464 - val_top_k_categorical_accuracy: 0.9543\n",
      "Epoch 18/20\n",
      "28709/28709 [==============================] - 12s - loss: 1.7504 - acc: 0.4678 - top_k_categorical_accuracy: 0.9574 - val_loss: 1.8050 - val_acc: 0.4480 - val_top_k_categorical_accuracy: 0.9546\n",
      "Epoch 19/20\n",
      "28709/28709 [==============================] - 12s - loss: 1.7469 - acc: 0.4693 - top_k_categorical_accuracy: 0.9578 - val_loss: 1.8029 - val_acc: 0.4475 - val_top_k_categorical_accuracy: 0.9549\n",
      "Epoch 20/20\n",
      "28709/28709 [==============================] - 12s - loss: 1.7436 - acc: 0.4705 - top_k_categorical_accuracy: 0.9578 - val_loss: 1.8017 - val_acc: 0.4466 - val_top_k_categorical_accuracy: 0.9546\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f9de802f950>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Test loss:', 1.7850312265920651)\n",
      "('Test accuracy:', 0.45249373085255012)\n"
     ]
    }
   ],
   "source": [
    "def test_resnet18():\n",
    "    model = ResnetBuilder.build_resnet_18((1, 48, 48), 7)\n",
    "    #_test_model_compile(model)\n",
    "    model.summary()\n",
    "    sgd= SGD(lr=0.1,momentum=0.99, decay=0.9999, nesterov=True)\n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer=sgd,metrics=['acc',top_k_categorical_accuracy])\n",
    "    \n",
    "    print('--Non Training--')\n",
    "    score = model.evaluate(x_train, to_categorical(y_train), verbose=0)\n",
    "    print('Train loss:', score[0])\n",
    "    print('Train accuracy:', score[1])\n",
    "\n",
    "    \n",
    "    batch_size = 128\n",
    "    EPOCH = 20\n",
    "    \n",
    "    results = []\n",
    "    start_time = time.time()\n",
    "\n",
    "    history = model.fit(x_train, to_categorical(y_train),\n",
    "              batch_size=batch_size,\n",
    "              epochs=EPOCH,\n",
    "              validation_data=(x_vali, to_categorical(y_vali)))\n",
    "    \n",
    "    \n",
    "    average_time_per_epoch = (time.time() - start_time) / EPOCH\n",
    "    results.append((history, average_time_per_epoch))\n",
    "    plt.style.use('ggplot')\n",
    "    ax1 = plt.subplot2grid((2, 2), (0, 0))\n",
    "    ax1.set_title('Accuracy')\n",
    "    ax1.set_ylabel('Accuracy')\n",
    "    ax1.set_xlabel('Epochs')\n",
    "    ax2 = plt.subplot2grid((2, 2), (1, 0))\n",
    "    ax2.set_title('Loss')\n",
    "    ax2.set_ylabel('Loss')\n",
    "    ax2.set_xlabel('Epochs')\n",
    "    ax3 = plt.subplot2grid((2, 2), (0, 1), rowspan=2)\n",
    "    ax3.set_title('Time')\n",
    "    ax3.set_ylabel('Seconds')\n",
    "\n",
    "    for result in results:\n",
    "        ax1.plot(result[0].epoch, result[0].history['val_acc'], label='Vali')\n",
    "        ax1.plot(result[0].epoch, result[0].history['acc'], label='Train')\n",
    "        ax2.plot(result[0].epoch, result[0].history['val_loss'], label='Vali')\n",
    "        ax2.plot(result[0].epoch, result[0].history['loss'], label='Train')\n",
    "\n",
    "    ax1.legend()\n",
    "    ax2.legend()\n",
    "    ax3.bar(np.arange(len(results)), [x[1] for x in results],\n",
    "            align='center')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    score = model.evaluate(x_test, to_categorical(y_test), verbose=0)\n",
    "    print('Test loss:', score[0])\n",
    "    print('Test accuracy:', score[1])\n",
    "\n",
    "test_resnet18()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
