{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Reproducing paper:\n",
    "Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun. \"Identity Mappings in Deep Residual Networks\"\n",
    "'''\n",
    "import mxnet as mx\n",
    "\n",
    "def residual_unit(data, num_filter, stride, dim_match, name, bottle_neck=True, bn_mom=0.9, workspace=512, memonger=False):\n",
    "    \"\"\"Return ResNet Unit symbol for building ResNet\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : str\n",
    "        Input data\n",
    "    num_filter : int\n",
    "        Number of output channels\n",
    "    bnf : int\n",
    "        Bottle neck channels factor with regard to num_filter\n",
    "    stride : tupe\n",
    "        Stride used in convolution\n",
    "    dim_match : Boolen\n",
    "        True means channel number between input and output is the same, otherwise means differ\n",
    "    name : str\n",
    "        Base name of the operators\n",
    "    workspace : int\n",
    "        Workspace used in convolution operator\n",
    "    \"\"\"\n",
    "    if bottle_neck:\n",
    "        # the same as https://github.com/facebook/fb.resnet.torch#notes, a bit difference with origin paper\n",
    "        bn1 = mx.sym.BatchNorm(data=data, fix_gamma=False, eps=2e-5, momentum=bn_mom, name=name + '_bn1')\n",
    "        act1 = mx.sym.Activation(data=bn1, act_type='relu', name=name + '_relu1')\n",
    "        conv1 = mx.sym.Convolution(data=act1, num_filter=int(num_filter*0.25), kernel=(1,1), stride=(1,1), pad=(0,0),\n",
    "                                      no_bias=True, workspace=workspace, name=name + '_conv1')\n",
    "        bn2 = mx.sym.BatchNorm(data=conv1, fix_gamma=False, eps=2e-5, momentum=bn_mom, name=name + '_bn2')\n",
    "        act2 = mx.sym.Activation(data=bn2, act_type='relu', name=name + '_relu2')\n",
    "        conv2 = mx.sym.Convolution(data=act2, num_filter=int(num_filter*0.25), kernel=(3,3), stride=stride, pad=(1,1),\n",
    "                                      no_bias=True, workspace=workspace, name=name + '_conv2')\n",
    "        bn3 = mx.sym.BatchNorm(data=conv2, fix_gamma=False, eps=2e-5, momentum=bn_mom, name=name + '_bn3')\n",
    "        act3 = mx.sym.Activation(data=bn3, act_type='relu', name=name + '_relu3')\n",
    "        conv3 = mx.sym.Convolution(data=act3, num_filter=num_filter, kernel=(1,1), stride=(1,1), pad=(0,0), no_bias=True,\n",
    "                                   workspace=workspace, name=name + '_conv3')\n",
    "        if dim_match:\n",
    "            shortcut = data\n",
    "        else:\n",
    "            shortcut = mx.sym.Convolution(data=act1, num_filter=num_filter, kernel=(1,1), stride=stride, no_bias=True,\n",
    "                                            workspace=workspace, name=name+'_sc')\n",
    "        if memonger:\n",
    "            shortcut._set_attr(mirror_stage='True')\n",
    "        return conv3 + shortcut\n",
    "    else:\n",
    "        bn1 = mx.sym.BatchNorm(data=data, fix_gamma=False, momentum=bn_mom, eps=2e-5, name=name + '_bn1')\n",
    "        act1 = mx.sym.Activation(data=bn1, act_type='relu', name=name + '_relu1')\n",
    "        conv1 = mx.sym.Convolution(data=act1, num_filter=num_filter, kernel=(3,3), stride=stride, pad=(1,1),\n",
    "                                      no_bias=True, workspace=workspace, name=name + '_conv1')\n",
    "        bn2 = mx.sym.BatchNorm(data=conv1, fix_gamma=False, momentum=bn_mom, eps=2e-5, name=name + '_bn2')\n",
    "        act2 = mx.sym.Activation(data=bn2, act_type='relu', name=name + '_relu2')\n",
    "        conv2 = mx.sym.Convolution(data=act2, num_filter=num_filter, kernel=(3,3), stride=(1,1), pad=(1,1),\n",
    "                                      no_bias=True, workspace=workspace, name=name + '_conv2')\n",
    "        if dim_match:\n",
    "            shortcut = data\n",
    "        else:\n",
    "            shortcut = mx.sym.Convolution(data=act1, num_filter=num_filter, kernel=(1,1), stride=stride, no_bias=True,\n",
    "                                            workspace=workspace, name=name+'_sc')\n",
    "        if memonger:\n",
    "            shortcut._set_attr(mirror_stage='True')\n",
    "        return conv2 + shortcut\n",
    "\n",
    "def resnet(units, num_stage, filter_list, num_class, data_type, bottle_neck=True, bn_mom=0.9, workspace=512, memonger=False):\n",
    "    \"\"\"Return ResNet symbol of cifar10 and imagenet\n",
    "    Parameters\n",
    "    ----------\n",
    "    units : list\n",
    "        Number of units in each stage\n",
    "    num_stage : int\n",
    "        Number of stage\n",
    "    filter_list : list\n",
    "        Channel size of each stage\n",
    "    num_class : int\n",
    "        Ouput size of symbol\n",
    "    dataset : str\n",
    "        Dataset type, only cifar10 and imagenet supports\n",
    "    workspace : int\n",
    "        Workspace used in convolution operator\n",
    "    \"\"\"\n",
    "    num_unit = len(units)\n",
    "    assert(num_unit == num_stage)\n",
    "    data = mx.sym.Variable(name='data')\n",
    "    data = mx.sym.BatchNorm(data=data, fix_gamma=True, eps=2e-5, momentum=bn_mom, name='bn_data')\n",
    "    if data_type == 'cifar10':\n",
    "        body = mx.sym.Convolution(data=data, num_filter=filter_list[0], kernel=(3, 3), stride=(1,1), pad=(1, 1),\n",
    "                                  no_bias=True, name=\"conv0\", workspace=workspace)\n",
    "    elif data_type == 'imagenet':\n",
    "        body = mx.sym.Convolution(data=data, num_filter=filter_list[0], kernel=(7, 7), stride=(2,2), pad=(3, 3),\n",
    "                                  no_bias=True, name=\"conv0\", workspace=workspace)\n",
    "        body = mx.sym.BatchNorm(data=body, fix_gamma=False, eps=2e-5, momentum=bn_mom, name='bn0')\n",
    "        body = mx.sym.Activation(data=body, act_type='relu', name='relu0')\n",
    "        body = mx.symbol.Pooling(data=body, kernel=(3, 3), stride=(2,2), pad=(1,1), pool_type='max')\n",
    "    else:\n",
    "         raise ValueError(\"do not support {} yet\".format(data_type))\n",
    "    for i in range(num_stage):\n",
    "        body = residual_unit(body, filter_list[i+1], (1 if i==0 else 2, 1 if i==0 else 2), False,\n",
    "                             name='stage%d_unit%d' % (i + 1, 1), bottle_neck=bottle_neck, workspace=workspace,\n",
    "                             memonger=memonger)\n",
    "        for j in range(units[i]-1):\n",
    "            body = residual_unit(body, filter_list[i+1], (1,1), True, name='stage%d_unit%d' % (i + 1, j + 2),\n",
    "                                 bottle_neck=bottle_neck, workspace=workspace, memonger=memonger)\n",
    "    bn1 = mx.sym.BatchNorm(data=body, fix_gamma=False, eps=2e-5, momentum=bn_mom, name='bn1')\n",
    "    relu1 = mx.sym.Activation(data=bn1, act_type='relu', name='relu1')\n",
    "    # Although kernel is not used here when global_pool=True, we should put one\n",
    "    pool1 = mx.symbol.Pooling(data=relu1, global_pool=True, kernel=(7, 7), pool_type='avg', name='pool1')\n",
    "    flat = mx.symbol.Flatten(data=pool1)\n",
    "    fc1 = mx.symbol.FullyConnected(data=flat, num_hidden=num_class, name='fc1')\n",
    "    return mx.symbol.SoftmaxOutput(data=fc1, name='softmax')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    \n",
    "    ## Data Type: cifar-10\n",
    "    aug_level = 1\n",
    "    num_classes = 8\n",
    "    depth = 164\n",
    "    bn_mom = 0.9\n",
    "    workspace = 512\n",
    "    memonger = False\n",
    "    # depth should be one of 110, 164, 1001,...,which is should fit (args.depth-2)%9 == 0\n",
    "    if((depth-2)%9 == 0 and depth >= 164):\n",
    "        per_unit = [(depth-2)/9]\n",
    "        filter_list = [16, 64, 128, 256]\n",
    "        bottle_neck = True\n",
    "    elif((depth-2)%6 == 0 and depth < 164):\n",
    "        per_unit = [(depth-2)/6]\n",
    "        filter_list = [16, 16, 32, 64]\n",
    "        bottle_neck = False\n",
    "    else:\n",
    "        raise ValueError(\"no experiments done on detph {}, you can do it youself\".format(depth))\n",
    "    units = per_unit*3\n",
    "    units = [int(i) for i in units]\n",
    "    \n",
    "    \n",
    "    symbol = resnet(units=units, num_stage=3, filter_list=filter_list, num_class=num_classes,\n",
    "                    data_type=\"cifar10\", bottle_neck = bottle_neck, \n",
    "                    bn_mom=bn_mom, workspace=workspace,\n",
    "                    memonger = memonger)\n",
    "    print(symbol)\n",
    "    \n",
    "    ctx = mx.cpu()\n",
    "    epoch_size = 3\n",
    "    begin_epoch = 0\n",
    "    \n",
    "    train_iter = mx.io.ImageRecordIter(\n",
    "        path_imgrec = \"/home/jiaming/code/github/DeepGlint-Work/Facial/scripts/test.rec\", # The target record file.\n",
    "        path_imgidx = \"/home/jiaming/code/github/DeepGlint-Work/Facial/scripts/test.idx\",\n",
    "        data_shape=(3, 224, 224), # Output data shape; 227x227 region will be cropped from the original image.\n",
    "        batch_size=4, # Number of items per batch.\n",
    "        resize=256, # Resize the shorter edge to 256 before cropping.\n",
    "        rand_crop = True,\n",
    "        rand_mirror = True,\n",
    "        shuffle = True\n",
    "    )\n",
    "    \n",
    "    test_iter = mx.io.ImageRecordIter(\n",
    "        path_imgrec = \"/home/jiaming/code/github/DeepGlint-Work/Facial/scripts/vali.rec\", # The target record file.\n",
    "        path_imgidx = \"/home/jiaming/code/github/DeepGlint-Work/Facial/scripts/vali.idx\",\n",
    "        data_shape=(3, 224, 224), # Output data shape; 227x227 region will be cropped from the original image.\n",
    "        batch_size=4, # Number of items per batch.\n",
    "        resize=256, # Resize the shorter edge to 256 before cropping.\n",
    "        shuffle = False,\n",
    "        rand_crop = False,\n",
    "        rand_mirror = False,\n",
    "    )\n",
    "    \n",
    "    model = mx.model.FeedForward(\n",
    "        ctx                 = mx.cpu(),\n",
    "        symbol              = symbol,\n",
    "        arg_params          = None,#arg_params,\n",
    "        aux_params          = None,#aux_params,\n",
    "        num_epoch           = 3,\n",
    "        begin_epoch         = 0,\n",
    "        learning_rate       = 0.1,\n",
    "        momentum            = 0.9,#args.mom,\n",
    "        wd                  = 0.00001,#wd: weight decay\n",
    "        optimizer           = 'sgd',\n",
    "        # optimizer          = 'sgd',\n",
    "        initializer         = mx.init.Xavier(rnd_type='gaussian', factor_type=\"in\", magnitude=2),\n",
    "        #lr_scheduler        = multi_factor_scheduler(begin_epoch, epoch_size, step=[120, 160], factor=0.1)\n",
    "        #                     if args.data_type=='cifar10' else\n",
    "        #                     multi_factor_scheduler(begin_epoch, epoch_size, step=[30, 60, 90], factor=0.1),\n",
    "        )\n",
    "\n",
    "    \n",
    "    model.fit(\n",
    "        X                  = train_iter,\n",
    "        eval_data          = test_iter,\n",
    "        eval_metric        = ['acc', 'ce'], #if args.data_type=='cifar10' else\n",
    "                             #['acc', mx.metric.create('top_k_accuracy', top_k = 5)],\n",
    "        #kvstore            = kv,\n",
    "        batch_end_callback = mx.callback.Speedometer(3,50))#,args.batch_size, args.frequent),\n",
    "        #epoch_end_callback = checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Symbol softmax>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:69: DeprecationWarning: \u001b[91mmxnet.model.FeedForward has been deprecated. Please use mxnet.mod.Module instead.\u001b[0m\n",
      "/home/jiaming/.local/lib/python3.6/site-packages/mxnet/model.py:591: DeprecationWarning: \u001b[91mCalling initializer with init(str, NDArray) has been deprecated.please use init(mx.init.InitDesc(...), NDArray) instead.\u001b[0m\n",
      "  self.initializer(k, v)\n",
      "/home/jiaming/.local/lib/python3.6/site-packages/mxnet/model.py:597: DeprecationWarning: \u001b[91mCalling initializer with init(str, NDArray) has been deprecated.please use init(mx.init.InitDesc(...), NDArray) instead.\u001b[0m\n",
      "  self.initializer(k, v)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
