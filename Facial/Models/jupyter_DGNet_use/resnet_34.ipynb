{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## First Part: Load the data: \n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "def shuffle(x_,y_):\n",
    "    s = np.arange(x_.shape[0])\n",
    "    s = np.random.shuffle(s)\n",
    "\n",
    "    x_re = x_[s]\n",
    "    y_re = y_[s]\n",
    "\n",
    "    x_re = np.reshape(x_re,(len(x_),48,48))\n",
    "    y_re = np.reshape(y_re,(len(y_)))\n",
    "    return x_re,y_re\n",
    "\n",
    "def read_fer(path):\n",
    "    # train_path = \"C:\\\\Users\\\\Jiaming Nie\\\\Documents\\\\Work-DeepGlint\\Facial\\datasets\\\\train.csv\"\n",
    "    data = pd.read_csv(path, dtype='a')\n",
    "    label = np.array(data['emotion'])\n",
    "    img_data = np.array(data['pixels'])\n",
    "\n",
    "    N_sample = label.size\n",
    "\n",
    "    x_data = np.zeros((N_sample, 48 * 48))\n",
    "    # train_label = np.zeros((N_sample, 7), dtype=int)\n",
    "    y_label = np.zeros(N_sample, dtype=int)\n",
    "    # print(train_label)\n",
    "\n",
    "    for i in range(N_sample):\n",
    "        x = img_data[i]\n",
    "        x = np.fromstring(x, dtype=float, sep=' ')\n",
    "        x_max = x.max()\n",
    "        x = x / (x_max + 0.0001)\n",
    "        # print x_max\n",
    "        # print x\n",
    "        x_data[i] = x\n",
    "        y_label[i] = int(label[i])\n",
    "        # train_label[i, label[i]] = 1 #This step seems direct one-hot encoding\n",
    "        # print(y_label[i])\n",
    "        #    img_x = np.reshape(x, (48, 48))\n",
    "        #    plt.subplot(10,10,i+1)\n",
    "        #    plt.axis('off')\n",
    "        #    plt.imshow(img_x, plt.cm.gray)\n",
    "\n",
    "    x_data = np.reshape(x_data,(len(x_data),48,48))\n",
    "    return x_data, y_label\n",
    "\n",
    "def ReadData_fer():\n",
    "    # ubuntu path\n",
    "    #path_train = \"/home/jiaming/code/DeepGlint-Work/Facial/datasets/train.csv\"\n",
    "    #path_test = \"/home/jiaming/code/DeepGlint-Work/Facial/datasets/test.csv\"\n",
    "\n",
    "    # windows path\n",
    "    path_train = \"/train/trainset/1/train.csv\"\n",
    "    path_test = \"/train/trainset/1/test.csv\"\n",
    "    path_vali = \"/train/trainset/1/val.csv\"\n",
    "    \n",
    "    x_train, y_train = read_fer(path_train)\n",
    "    x_test, y_test = read_fer(path_test)\n",
    "    x_vali, y_vali = read_fer(path_vali)\n",
    "\n",
    "    x_train, y_train = shuffle(x_train, y_train)\n",
    "    x_test, y_test = shuffle(x_test, y_test)\n",
    "    x_vali, y_vali = shuffle(x_vali, y_vali)\n",
    "\n",
    "    return x_train,y_train,x_test,y_test,x_vali,y_vali\n",
    "\n",
    "def zca_whitening(X):\n",
    "    \"\"\"\n",
    "        Function to compute ZCA whitening matrix (aka Mahalanobis whitening).\n",
    "        INPUT:  X: [M x N] matrix.\n",
    "            Rows: Variables\n",
    "            Columns: Observations\n",
    "        OUTPUT: ZCAMatrix: [M x M] matrix\n",
    "        \"\"\"\n",
    "    mean_ = np.mean(X)\n",
    "    X = X - mean_\n",
    "    # Covariance matrix [column-wise variables]: Sigma = (X-mu)' * (X-mu) / N\n",
    "    sigma = np.cov(X, rowvar=True)  # [M x M]\n",
    "    # Singular Value Decomposition. X = U * np.diag(S) * V\n",
    "    U, S, V = np.linalg.svd(sigma)\n",
    "    # U: [M x M] eigenvectors of sigma.\n",
    "    # S: [M x 1] eigenvalues of sigma.\n",
    "    # V: [M x M] transpose of U\n",
    "    # Whitening constant: prevents division by zero\n",
    "    epsilon = 0.1\n",
    "    # ZCA Whitening matrix: U * Lambda * U'\n",
    "    ZCAMatrix = np.dot(U, np.dot(np.diag(1.0 / np.sqrt(S + epsilon)), U.T))  # [M x M]\n",
    "    return ZCAMatrix\n",
    "\n",
    "def normalization(x_):\n",
    "\n",
    "    length = len(x_)\n",
    "\n",
    "    for i in range(length):\n",
    "        x_[i] = zca_whitening(x_[i])\n",
    "\n",
    "    return x_\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,y_train,x_test,y_test,x_vali,y_vali = ReadData_fer()\n",
    "\n",
    "# Normalization\n",
    "#x_train = normalization(x_train)\n",
    "#x_test = normalization(x_test)\n",
    "#x_vali = normalization(x_vali)\n",
    "\n",
    "x_train = x_train.reshape((len(x_train), 48, 48, 1))\n",
    "x_test = x_test.reshape((len(x_test), 48, 48, 1))\n",
    "x_vali = x_vali.reshape((len(x_vali),48,48,1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# coding=utf-8, keras model implementation \n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Dropout, BatchNormalization, Conv2D, MaxPooling2D, AveragePooling2D, concatenate, \\\n",
    "    Activation, ZeroPadding2D\n",
    "from keras.layers import add, Flatten\n",
    "from keras.utils import plot_model\n",
    "from keras.metrics import top_k_categorical_accuracy\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import load_model\n",
    "from keras.utils import to_categorical\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import tensorflow as tf\n",
    "import keras.backend.tensorflow_backend as KTF  \n",
    "KTF.set_session(tf.Session(config=tf.ConfigProto(device_count={'gpu':0})))  \n",
    "\n",
    "#THEANO_FLAGS=device=gpu, floatX=32\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global Constants\n",
    "NB_CLASS=7\n",
    "IM_WIDTH=48\n",
    "IM_HEIGHT=48\n",
    "CHANNEL = 1\n",
    "\n",
    "batch_size=128\n",
    "EPOCH=20\n",
    "\n",
    "\n",
    "def Conv2d_BN(x, nb_filter, kernel_size, strides=(1, 1), padding='same', name=None):\n",
    "    if name is not None:\n",
    "        bn_name = name + '_bn'\n",
    "        conv_name = name + '_conv'\n",
    "    else:\n",
    "        bn_name = None\n",
    "        conv_name = None\n",
    "\n",
    "    x = Conv2D(nb_filter, kernel_size, padding=padding, strides=strides, activation='relu', name=conv_name)(x)\n",
    "    x = BatchNormalization(axis=3, name=bn_name)(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def identity_Block(inpt, nb_filter, kernel_size, strides=(1, 1), with_conv_shortcut=False):\n",
    "    x = Conv2d_BN(inpt, nb_filter=nb_filter, kernel_size=kernel_size, strides=strides, padding='same')\n",
    "    x = Conv2d_BN(x, nb_filter=nb_filter, kernel_size=kernel_size, padding='same')\n",
    "    if with_conv_shortcut:\n",
    "        shortcut = Conv2d_BN(inpt, nb_filter=nb_filter, strides=strides, kernel_size=kernel_size)\n",
    "        x = add([x, shortcut])\n",
    "        return x\n",
    "    else:\n",
    "        x = add([x, inpt])\n",
    "        return x\n",
    "\n",
    "def bottleneck_Block(inpt,nb_filters,strides=(1,1),with_conv_shortcut=False):\n",
    "    k1,k2,k3=nb_filters\n",
    "    x = Conv2d_BN(inpt, nb_filter=k1, kernel_size=1, strides=strides, padding='same')\n",
    "    x = Conv2d_BN(x, nb_filter=k2, kernel_size=3, padding='same')\n",
    "    x = Conv2d_BN(x, nb_filter=k3, kernel_size=1, padding='same')\n",
    "    if with_conv_shortcut:\n",
    "        shortcut = Conv2d_BN(inpt, nb_filter=k3, strides=strides, kernel_size=1)\n",
    "        x = add([x, shortcut])\n",
    "        return x\n",
    "    else:\n",
    "        x = add([x, inpt])\n",
    "        return x\n",
    "\n",
    "def resnet_34(width,height,channel,classes):\n",
    "    inpt = Input(shape=(width, height, channel))\n",
    "    x = ZeroPadding2D((3, 3))(inpt)\n",
    "\n",
    "    #conv1\n",
    "    x = Conv2d_BN(x, nb_filter=64, kernel_size=(7, 7), strides=(2, 2), padding='valid')\n",
    "    x = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding='same')(x)\n",
    "\n",
    "    #conv2_x\n",
    "    x = identity_Block(x, nb_filter=64, kernel_size=(3, 3))\n",
    "    x = identity_Block(x, nb_filter=64, kernel_size=(3, 3))\n",
    "    x = identity_Block(x, nb_filter=64, kernel_size=(3, 3))\n",
    "\n",
    "    #conv3_x\n",
    "    x = identity_Block(x, nb_filter=128, kernel_size=(3, 3), strides=(2, 2), with_conv_shortcut=True)\n",
    "    x = identity_Block(x, nb_filter=128, kernel_size=(3, 3))\n",
    "    x = identity_Block(x, nb_filter=128, kernel_size=(3, 3))\n",
    "    x = identity_Block(x, nb_filter=128, kernel_size=(3, 3))\n",
    "\n",
    "    #conv4_x\n",
    "    x = identity_Block(x, nb_filter=256, kernel_size=(3, 3), strides=(2, 2), with_conv_shortcut=True)\n",
    "    x = identity_Block(x, nb_filter=256, kernel_size=(3, 3))\n",
    "    x = identity_Block(x, nb_filter=256, kernel_size=(3, 3))\n",
    "    x = identity_Block(x, nb_filter=256, kernel_size=(3, 3))\n",
    "    x = identity_Block(x, nb_filter=256, kernel_size=(3, 3))\n",
    "    x = identity_Block(x, nb_filter=256, kernel_size=(3, 3))\n",
    "\n",
    "    #conv5_x\n",
    "    x = identity_Block(x, nb_filter=512, kernel_size=(3, 3), strides=(2, 2), with_conv_shortcut=True)\n",
    "    x = identity_Block(x, nb_filter=512, kernel_size=(3, 3))\n",
    "    x = identity_Block(x, nb_filter=512, kernel_size=(3, 3))\n",
    "    #x = AveragePooling2D(pool_size=(7, 7))(x)\n",
    "    x = AveragePooling2D(pool_size=(2,2))(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(classes, activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs=inpt, outputs=x)\n",
    "    return model\n",
    "\n",
    "def acc_top2(y_true, y_pred):\n",
    "    return top_k_categorical_accuracy(y_true, y_pred, k=3)\n",
    "\n",
    "\n",
    "def check_print():\n",
    "    # Create a Keras Model\n",
    "    model = resnet_34(IM_WIDTH,IM_HEIGHT,1,NB_CLASS)\n",
    "    model.summary()\n",
    "    # Save a PNG of the Model Build\n",
    "    #plot_model(model, to_file='resnet.png')\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc',top_k_categorical_accuracy])\n",
    "    print('Model Compiled')\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28709, 48, 48, 1)\n",
      "(28709,)\n",
      "(3589, 48, 48, 1)\n",
      "(3589,)\n",
      "(3589, 48, 48, 1)\n",
      "(3589,)\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_1 (InputLayer)             (None, 48, 48, 1)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "zero_padding2d_1 (ZeroPadding2D) (None, 54, 54, 1)     0           input_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)                (None, 24, 24, 64)    3200        zero_padding2d_1[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNorm (None, 24, 24, 64)    256         conv2d_1[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)   (None, 12, 12, 64)    0           batch_normalization_1[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)                (None, 12, 12, 64)    36928       max_pooling2d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNorm (None, 12, 12, 64)    256         conv2d_2[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)                (None, 12, 12, 64)    36928       batch_normalization_2[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNorm (None, 12, 12, 64)    256         conv2d_3[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "add_1 (Add)                      (None, 12, 12, 64)    0           batch_normalization_3[0][0]      \n",
      "                                                                   max_pooling2d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)                (None, 12, 12, 64)    36928       add_1[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNorm (None, 12, 12, 64)    256         conv2d_4[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)                (None, 12, 12, 64)    36928       batch_normalization_4[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNorm (None, 12, 12, 64)    256         conv2d_5[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "add_2 (Add)                      (None, 12, 12, 64)    0           batch_normalization_5[0][0]      \n",
      "                                                                   add_1[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)                (None, 12, 12, 64)    36928       add_2[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNorm (None, 12, 12, 64)    256         conv2d_6[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)                (None, 12, 12, 64)    36928       batch_normalization_6[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNorm (None, 12, 12, 64)    256         conv2d_7[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "add_3 (Add)                      (None, 12, 12, 64)    0           batch_normalization_7[0][0]      \n",
      "                                                                   add_2[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)                (None, 6, 6, 128)     73856       add_3[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNorm (None, 6, 6, 128)     512         conv2d_8[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)                (None, 6, 6, 128)     147584      batch_normalization_8[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)               (None, 6, 6, 128)     73856       add_3[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNorm (None, 6, 6, 128)     512         conv2d_9[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNor (None, 6, 6, 128)     512         conv2d_10[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "add_4 (Add)                      (None, 6, 6, 128)     0           batch_normalization_9[0][0]      \n",
      "                                                                   batch_normalization_10[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)               (None, 6, 6, 128)     147584      add_4[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNor (None, 6, 6, 128)     512         conv2d_11[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)               (None, 6, 6, 128)     147584      batch_normalization_11[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNor (None, 6, 6, 128)     512         conv2d_12[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "add_5 (Add)                      (None, 6, 6, 128)     0           batch_normalization_12[0][0]     \n",
      "                                                                   add_4[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)               (None, 6, 6, 128)     147584      add_5[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNor (None, 6, 6, 128)     512         conv2d_13[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)               (None, 6, 6, 128)     147584      batch_normalization_13[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNor (None, 6, 6, 128)     512         conv2d_14[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "add_6 (Add)                      (None, 6, 6, 128)     0           batch_normalization_14[0][0]     \n",
      "                                                                   add_5[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)               (None, 6, 6, 128)     147584      add_6[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNor (None, 6, 6, 128)     512         conv2d_15[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)               (None, 6, 6, 128)     147584      batch_normalization_15[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNor (None, 6, 6, 128)     512         conv2d_16[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "add_7 (Add)                      (None, 6, 6, 128)     0           batch_normalization_16[0][0]     \n",
      "                                                                   add_6[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)               (None, 3, 3, 256)     295168      add_7[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNor (None, 3, 3, 256)     1024        conv2d_17[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)               (None, 3, 3, 256)     590080      batch_normalization_17[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)               (None, 3, 3, 256)     295168      add_7[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNor (None, 3, 3, 256)     1024        conv2d_18[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNor (None, 3, 3, 256)     1024        conv2d_19[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "add_8 (Add)                      (None, 3, 3, 256)     0           batch_normalization_18[0][0]     \n",
      "                                                                   batch_normalization_19[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)               (None, 3, 3, 256)     590080      add_8[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNor (None, 3, 3, 256)     1024        conv2d_20[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)               (None, 3, 3, 256)     590080      batch_normalization_20[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNor (None, 3, 3, 256)     1024        conv2d_21[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "add_9 (Add)                      (None, 3, 3, 256)     0           batch_normalization_21[0][0]     \n",
      "                                                                   add_8[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)               (None, 3, 3, 256)     590080      add_9[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNor (None, 3, 3, 256)     1024        conv2d_22[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)               (None, 3, 3, 256)     590080      batch_normalization_22[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNor (None, 3, 3, 256)     1024        conv2d_23[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "add_10 (Add)                     (None, 3, 3, 256)     0           batch_normalization_23[0][0]     \n",
      "                                                                   add_9[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)               (None, 3, 3, 256)     590080      add_10[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNor (None, 3, 3, 256)     1024        conv2d_24[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)               (None, 3, 3, 256)     590080      batch_normalization_24[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNor (None, 3, 3, 256)     1024        conv2d_25[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "add_11 (Add)                     (None, 3, 3, 256)     0           batch_normalization_25[0][0]     \n",
      "                                                                   add_10[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)               (None, 3, 3, 256)     590080      add_11[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNor (None, 3, 3, 256)     1024        conv2d_26[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)               (None, 3, 3, 256)     590080      batch_normalization_26[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNor (None, 3, 3, 256)     1024        conv2d_27[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "add_12 (Add)                     (None, 3, 3, 256)     0           batch_normalization_27[0][0]     \n",
      "                                                                   add_11[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)               (None, 3, 3, 256)     590080      add_12[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNor (None, 3, 3, 256)     1024        conv2d_28[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)               (None, 3, 3, 256)     590080      batch_normalization_28[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNor (None, 3, 3, 256)     1024        conv2d_29[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "add_13 (Add)                     (None, 3, 3, 256)     0           batch_normalization_29[0][0]     \n",
      "                                                                   add_12[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)               (None, 2, 2, 512)     1180160     add_13[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNor (None, 2, 2, 512)     2048        conv2d_30[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)               (None, 2, 2, 512)     2359808     batch_normalization_30[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)               (None, 2, 2, 512)     1180160     add_13[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNor (None, 2, 2, 512)     2048        conv2d_31[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNor (None, 2, 2, 512)     2048        conv2d_32[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "add_14 (Add)                     (None, 2, 2, 512)     0           batch_normalization_31[0][0]     \n",
      "                                                                   batch_normalization_32[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)               (None, 2, 2, 512)     2359808     add_14[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNor (None, 2, 2, 512)     2048        conv2d_33[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)               (None, 2, 2, 512)     2359808     batch_normalization_33[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNor (None, 2, 2, 512)     2048        conv2d_34[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "add_15 (Add)                     (None, 2, 2, 512)     0           batch_normalization_34[0][0]     \n",
      "                                                                   add_14[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)               (None, 2, 2, 512)     2359808     add_15[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNor (None, 2, 2, 512)     2048        conv2d_35[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)               (None, 2, 2, 512)     2359808     batch_normalization_35[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNor (None, 2, 2, 512)     2048        conv2d_36[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "add_16 (Add)                     (None, 2, 2, 512)     0           batch_normalization_36[0][0]     \n",
      "                                                                   add_15[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePool (None, 1, 1, 512)     0           add_16[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)              (None, 512)           0           average_pooling2d_1[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 7)             3591        flatten_1[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 22,683,783\n",
      "Trainable params: 22,666,759\n",
      "Non-trainable params: 17,024\n",
      "____________________________________________________________________________________________________\n",
      "Model Compiled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 28709 samples, validate on 3589 samples\n",
      "Epoch 1/20\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "    print(x_train.shape)\n",
    "    print(y_train.shape)\n",
    "    print(x_test.shape)\n",
    "    print(y_test.shape)\n",
    "    print(x_vali.shape)\n",
    "    print(y_vali.shape)\n",
    "    #inpt = Input(shape=(48, 48, 1))\n",
    "    #print(inpt.shape)\n",
    "\n",
    "    #if os.path.exists('resnet_34.h5'):\n",
    "    #    model=load_model('resnet_34.h5')\n",
    "    #else:\n",
    "    model=check_print()\n",
    "\n",
    "    results = []\n",
    "    start_time = time.time()\n",
    "\n",
    "    history = model.fit(x_train, to_categorical(y_train),\n",
    "              batch_size = batch_size,\n",
    "              epochs= EPOCH,\n",
    "              validation_data=(x_vali,to_categorical(y_vali)))\n",
    "\n",
    "    #scores = model.evaluate(x_test,to_categorical(y_test))\n",
    "    #print(\"Accuracy: \",scores[1])\n",
    "    #print(\"Scores[0] :\",scores[0])\n",
    "\n",
    "    average_time_per_epoch = (time.time() - start_time) / EPOCH\n",
    "    results.append((history, average_time_per_epoch))\n",
    "    plt.style.use('ggplot')\n",
    "    ax1 = plt.subplot2grid((2, 2), (0, 0))\n",
    "    ax1.set_title('Accuracy')\n",
    "    ax1.set_ylabel('Accuracy')\n",
    "    ax1.set_xlabel('Epochs')\n",
    "    ax2 = plt.subplot2grid((2, 2), (1, 0))\n",
    "    ax2.set_title('Loss')\n",
    "    ax2.set_ylabel('Loss')\n",
    "    ax2.set_xlabel('Epochs')\n",
    "    ax3 = plt.subplot2grid((2, 2), (0, 1), rowspan=2)\n",
    "    ax3.set_title('Time')\n",
    "    ax3.set_ylabel('Seconds')\n",
    "\n",
    "    for result in results:\n",
    "        ax1.plot(result[0].epoch, result[0].history['val_acc'], label='Test')\n",
    "        ax1.plot(result[0].epoch, result[0].history['acc'], label='Train')\n",
    "        ax2.plot(result[0].epoch, result[0].history['val_loss'], label='Test')\n",
    "        ax2.plot(result[0].epoch, result[0].history['loss'], label='Train')\n",
    "\n",
    "    ax1.legend()\n",
    "    ax2.legend()\n",
    "    ax3.bar(np.arange(len(results)), [x[1] for x in results],\n",
    "            align='center')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    score = model.evaluate(x_test, to_categorical(y_test), verbose=0)\n",
    "    print('Test loss:', score[0])\n",
    "    print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
