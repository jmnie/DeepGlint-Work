{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## First Part: Load the data: \n",
    "# import pandas as pd \n",
    "# import numpy as np\n",
    "# import scipy.io as sio\n",
    "\n",
    "# def shuffle(x_,y_):\n",
    "#     s = np.arange(x_.shape[0])\n",
    "#     s = np.random.shuffle(s)\n",
    "\n",
    "#     x_re = x_[s]\n",
    "#     y_re = y_[s]\n",
    "\n",
    "#     x_re = np.reshape(x_re,(len(x_),48,48))\n",
    "#     y_re = np.reshape(y_re,(len(y_)))\n",
    "#     return x_re,y_re\n",
    "\n",
    "# def read_fer(path):\n",
    "#     # train_path = \"C:\\\\Users\\\\Jiaming Nie\\\\Documents\\\\Work-DeepGlint\\Facial\\datasets\\\\train.csv\"\n",
    "#     data = pd.read_csv(path, dtype='a')\n",
    "#     label = np.array(data['emotion'])\n",
    "#     img_data = np.array(data['pixels'])\n",
    "\n",
    "#     N_sample = label.size\n",
    "\n",
    "#     x_data = np.zeros((N_sample, 48 * 48))\n",
    "#     # train_label = np.zeros((N_sample, 7), dtype=int)\n",
    "#     y_label = np.zeros(N_sample, dtype=int)\n",
    "#     # print(train_label)\n",
    "\n",
    "#     for i in range(N_sample):\n",
    "#         x = img_data[i]\n",
    "#         x = np.fromstring(x, dtype=float, sep=' ')\n",
    "#         x_max = x.max()\n",
    "#         x = x / (x_max + 0.0001)\n",
    "#         # print x_max\n",
    "#         # print x\n",
    "#         x_data[i] = x\n",
    "#         y_label[i] = int(label[i])\n",
    "#         # train_label[i, label[i]] = 1 #This step seems direct one-hot encoding\n",
    "#         # print(y_label[i])\n",
    "#         #    img_x = np.reshape(x, (48, 48))\n",
    "#         #    plt.subplot(10,10,i+1)\n",
    "#         #    plt.axis('off')\n",
    "#         #    plt.imshow(img_x, plt.cm.gray)\n",
    "\n",
    "#     x_data = np.reshape(x_data,(len(x_data),48,48))\n",
    "#     return x_data, y_label\n",
    "\n",
    "# def ReadData_fer():\n",
    "#     # ubuntu path\n",
    "#     #path_train = \"/home/jiaming/code/DeepGlint-Work/Facial/datasets/train.csv\"\n",
    "#     #path_test = \"/home/jiaming/code/DeepGlint-Work/Facial/datasets/test.csv\"\n",
    "\n",
    "#     # windows path\n",
    "#     path_train = \"/train/trainset/1/train.csv\"\n",
    "#     path_test = \"/train/trainset/1/test.csv\"\n",
    "#     path_vali = \"/train/trainset/1/val.csv\"\n",
    "    \n",
    "#     x_train, y_train = read_fer(path_train)\n",
    "#     x_test, y_test = read_fer(path_test)\n",
    "#     x_vali, y_vali = read_fer(path_vali)\n",
    "\n",
    "#     x_train, y_train = shuffle(x_train, y_train)\n",
    "#     x_test, y_test = shuffle(x_test, y_test)\n",
    "#     x_vali, y_vali = shuffle(x_vali, y_vali)\n",
    "\n",
    "#     return x_train,y_train,x_test,y_test,x_vali,y_vali\n",
    "\n",
    "# def zca_whitening(X):\n",
    "#     \"\"\"\n",
    "#         Function to compute ZCA whitening matrix (aka Mahalanobis whitening).\n",
    "#         INPUT:  X: [M x N] matrix.\n",
    "#             Rows: Variables\n",
    "#             Columns: Observations\n",
    "#         OUTPUT: ZCAMatrix: [M x M] matrix\n",
    "#         \"\"\"\n",
    "#     mean_ = np.mean(X)\n",
    "#     X = X - mean_\n",
    "#     # Covariance matrix [column-wise variables]: Sigma = (X-mu)' * (X-mu) / N\n",
    "#     sigma = np.cov(X, rowvar=True)  # [M x M]\n",
    "#     # Singular Value Decomposition. X = U * np.diag(S) * V\n",
    "#     U, S, V = np.linalg.svd(sigma)\n",
    "#     # U: [M x M] eigenvectors of sigma.\n",
    "#     # S: [M x 1] eigenvalues of sigma.\n",
    "#     # V: [M x M] transpose of U\n",
    "#     # Whitening constant: prevents division by zero\n",
    "#     epsilon = 0.1\n",
    "#     # ZCA Whitening matrix: U * Lambda * U'\n",
    "#     ZCAMatrix = np.dot(U, np.dot(np.diag(1.0 / np.sqrt(S + epsilon)), U.T))  # [M x M]\n",
    "#     return ZCAMatrix\n",
    "\n",
    "# def normalization(x_):\n",
    "\n",
    "#     length = len(x_)\n",
    "\n",
    "#     for i in range(length):\n",
    "#         x_[i] = zca_whitening(x_[i])\n",
    "\n",
    "#     return x_\n",
    "\n",
    "# def oneHot(y_):\n",
    "#     # Function to encode output labels from number indexes \n",
    "#     # e.g.: [[5], [0], [3]] --> [[0, 0, 0, 0, 0, 1], [1, 0, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0]]\n",
    "#     y_ = y_.reshape(len(y_))\n",
    "#     n_values = int(np.max(y_)) + 1\n",
    "#     return np.eye(n_values)[np.array(y_, dtype=np.int32)]  # Returns FLOATS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28709, 48, 48, 1)\n",
      "(3589, 48, 48, 1)\n"
     ]
    }
   ],
   "source": [
    "# x_train,y_train,x_test,y_test,x_vali,y_vali = ReadData_fer()\n",
    "\n",
    "# # Normalization\n",
    "# #x_train = normalization(x_train)\n",
    "# #x_test = normalization(x_test)\n",
    "# #x_vali = normalization(x_vali)\n",
    "\n",
    "# x_train = x_train.reshape((len(x_train), 48, 48, 1))\n",
    "# x_test = x_test.reshape((len(x_test), 48, 48, 1))\n",
    "# x_vali = x_vali.reshape((len(x_vali),48,48,1))\n",
    "\n",
    "# train_name = 'x_train.mat'\n",
    "# vali_name = 'x_vali.mat'\n",
    "# test_name = 'x_test.mat'\n",
    "# sio.savemat(train_name,{'x_train': x_train})\n",
    "# sio.savemat(test_name,{'x_test': x_test})\n",
    "# sio.savemat(vali_name,{'x_vali': x_vali})\n",
    "# np.savetxt('y_train.txt',y_train)\n",
    "# np.savetxt('y_test.txt',y_test)\n",
    "# np.savetxt('y_vali.txt',y_vali)\n",
    "# print(x_train.shape)\n",
    "# print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Dropout, BatchNormalization, Conv2D, MaxPooling2D, AveragePooling2D, concatenate, \\\n",
    "    Activation, ZeroPadding2D\n",
    "from keras.layers import Activation\n",
    "from keras.layers import add, Flatten\n",
    "#from keras.utils import plot_model\n",
    "from keras.metrics import top_k_categorical_accuracy\n",
    "#from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import load_model\n",
    "from keras.utils import to_categorical\n",
    "import os\n",
    "from keras.optimizers import *\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf  \n",
    "from keras.regularizers import *\n",
    "import scipy.io\n",
    "import keras.backend.tensorflow_backend as KTF  \n",
    "KTF.set_session(tf.Session(config=tf.ConfigProto(device_count={'gpu':0})))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=256\n",
    "EPOCH=20\n",
    "NB_CLASS=7\n",
    "IM_WIDTH=48\n",
    "IM_HEIGHT=48\n",
    "CHANNEL = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Conv2d_BN(x, nb_filter, kernel_size, strides=(1, 1), padding='same', name=None):\n",
    "    if name is not None:\n",
    "        bn_name = name + '_bn'\n",
    "        conv_name = name + '_conv'\n",
    "    else:\n",
    "        bn_name = None\n",
    "        conv_name = None\n",
    "\n",
    "    x = Conv2D(nb_filter, kernel_size, padding=padding, strides=strides, activation='relu', name=conv_name)(x)\n",
    "    #x = Conv2D(nb_filter, kernel_size, padding=padding, strides=strides, name=conv_name)(x)\n",
    "    #x = BatchNormalization(axis=3, name=bn_name)(x)\n",
    "    #x = Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def identity_Block(inpt, nb_filter, kernel_size, strides=(1, 1), with_conv_shortcut=False):\n",
    "    x = Conv2d_BN(inpt, nb_filter=nb_filter, kernel_size=kernel_size, strides=strides, padding='same')\n",
    "    x = Conv2d_BN(x, nb_filter=nb_filter, kernel_size=kernel_size, padding='same')\n",
    "    if with_conv_shortcut:\n",
    "        shortcut = Conv2d_BN(inpt, nb_filter=nb_filter, strides=strides, kernel_size=kernel_size)\n",
    "        x = add([x, shortcut])\n",
    "        return x\n",
    "    else:\n",
    "        x = add([x, inpt])\n",
    "        return x\n",
    "\n",
    "def bottleneck_Block(inpt,nb_filters,strides=(1,1),with_conv_shortcut=False):\n",
    "    k1,k2,k3=nb_filters\n",
    "    x = Conv2d_BN(inpt, nb_filter=k1, kernel_size=1, strides=strides, padding='same')\n",
    "    x = Conv2d_BN(x, nb_filter=k2, kernel_size=3, padding='same')\n",
    "    x = Conv2d_BN(x, nb_filter=k3, kernel_size=1, padding='same')\n",
    "    if with_conv_shortcut:\n",
    "        shortcut = Conv2d_BN(inpt, nb_filter=k3, strides=strides, kernel_size=1)\n",
    "        x = add([x, shortcut])\n",
    "        return x\n",
    "    else:\n",
    "        x = add([x, inpt])\n",
    "        return x\n",
    "\n",
    "def resnet_34(width,height,channel,classes):\n",
    "    inpt = Input(shape=(width, height, channel))\n",
    "    x = ZeroPadding2D((3, 3))(inpt)\n",
    "\n",
    "    #conv1\n",
    "    x = Conv2d_BN(x, nb_filter=64, kernel_size=(7, 7), strides=(2, 2), padding='valid')\n",
    "    x = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding='same')(x)\n",
    "\n",
    "    #conv2_x\n",
    "    x = identity_Block(x, nb_filter=64, kernel_size=(3, 3))\n",
    "    x = identity_Block(x, nb_filter=64, kernel_size=(3, 3))\n",
    "    x = identity_Block(x, nb_filter=64, kernel_size=(3, 3))\n",
    "\n",
    "    #conv3_x\n",
    "    x = identity_Block(x, nb_filter=128, kernel_size=(3, 3), strides=(2, 2), with_conv_shortcut=True)\n",
    "    x = identity_Block(x, nb_filter=128, kernel_size=(3, 3))\n",
    "    x = identity_Block(x, nb_filter=128, kernel_size=(3, 3))\n",
    "    x = identity_Block(x, nb_filter=128, kernel_size=(3, 3))\n",
    "    x = AveragePooling2D(pool_size=(6,6))(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    \n",
    "    #conv4_x\n",
    "    #x = identity_Block(x, nb_filter=256, kernel_size=(3, 3), strides=(2, 2), with_conv_shortcut=True)\n",
    "    #x = identity_Block(x, nb_filter=256, kernel_size=(3, 3))\n",
    "    #x = identity_Block(x, nb_filter=256, kernel_size=(3, 3))\n",
    "    #x = identity_Block(x, nb_filter=256, kernel_size=(3, 3))\n",
    "    #x = identity_Block(x, nb_filter=256, kernel_size=(3, 3))\n",
    "    #x = identity_Block(x, nb_filter=256, kernel_size=(3, 3))\n",
    "\n",
    "    #conv5_x\n",
    "    #x = identity_Block(x, nb_filter=512, kernel_size=(3, 3), strides=(2, 2), with_conv_shortcut=True)\n",
    "    #x = identity_Block(x, nb_filter=512, kernel_size=(3, 3))\n",
    "    #x = identity_Block(x, nb_filter=512, kernel_size=(3, 3))\n",
    "    #x = AveragePooling2D(pool_size=(7, 7))(x)\n",
    "    #x = AveragePooling2D(pool_size=(2,2))(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(classes, activation='softmax',kernel_regularizer=l2(1e-5))(x)\n",
    "\n",
    "    model = Model(inputs=inpt, outputs=x)\n",
    "    return model\n",
    "\n",
    "\n",
    "def acc_top2(y_true, y_pred):\n",
    "    return top_k_categorical_accuracy(y_true, y_pred, k=3)\n",
    "\n",
    "\n",
    "def check_print():\n",
    "    # Create a Keras Model\n",
    "    model = resnet_34(IM_WIDTH,IM_HEIGHT,1,NB_CLASS)\n",
    "    #model.summary()\n",
    "    # Save a PNG of the Model Build\n",
    "    #plot_model(model, to_file='resnet.png')\n",
    "    adam = Adam(lr=0.1, beta_1=0.9, beta_2=0.999, decay = 0.1/10, epsilon=1e-08)\n",
    "    #sgd = SGD(lr=0.1, momentum=0.0, decay=0.1/10, nesterov=False)\n",
    "    model.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['acc',top_k_categorical_accuracy])\n",
    "    print('Model Compiled')\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28709, 48, 48, 1)\n",
      "(3589, 48, 48, 1)\n",
      "Model Compiled\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_14 (InputLayer)            (None, 48, 48, 1)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "zero_padding2d_14 (ZeroPadding2D (None, 54, 54, 1)     0           input_14[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_199 (Conv2D)              (None, 24, 24, 64)    3200        zero_padding2d_14[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling2D)  (None, 12, 12, 64)    0           conv2d_199[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_200 (Conv2D)              (None, 12, 12, 64)    36928       max_pooling2d_14[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_201 (Conv2D)              (None, 12, 12, 64)    36928       conv2d_200[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "add_87 (Add)                     (None, 12, 12, 64)    0           conv2d_201[0][0]                 \n",
      "                                                                   max_pooling2d_14[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_202 (Conv2D)              (None, 12, 12, 64)    36928       add_87[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_203 (Conv2D)              (None, 12, 12, 64)    36928       conv2d_202[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "add_88 (Add)                     (None, 12, 12, 64)    0           conv2d_203[0][0]                 \n",
      "                                                                   add_87[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_204 (Conv2D)              (None, 12, 12, 64)    36928       add_88[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_205 (Conv2D)              (None, 12, 12, 64)    36928       conv2d_204[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "add_89 (Add)                     (None, 12, 12, 64)    0           conv2d_205[0][0]                 \n",
      "                                                                   add_88[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_206 (Conv2D)              (None, 6, 6, 128)     73856       add_89[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_207 (Conv2D)              (None, 6, 6, 128)     147584      conv2d_206[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_208 (Conv2D)              (None, 6, 6, 128)     73856       add_89[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "add_90 (Add)                     (None, 6, 6, 128)     0           conv2d_207[0][0]                 \n",
      "                                                                   conv2d_208[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_209 (Conv2D)              (None, 6, 6, 128)     147584      add_90[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_210 (Conv2D)              (None, 6, 6, 128)     147584      conv2d_209[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "add_91 (Add)                     (None, 6, 6, 128)     0           conv2d_210[0][0]                 \n",
      "                                                                   add_90[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_211 (Conv2D)              (None, 6, 6, 128)     147584      add_91[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_212 (Conv2D)              (None, 6, 6, 128)     147584      conv2d_211[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "add_92 (Add)                     (None, 6, 6, 128)     0           conv2d_212[0][0]                 \n",
      "                                                                   add_91[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_213 (Conv2D)              (None, 6, 6, 128)     147584      add_92[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_214 (Conv2D)              (None, 6, 6, 128)     147584      conv2d_213[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "add_93 (Add)                     (None, 6, 6, 128)     0           conv2d_214[0][0]                 \n",
      "                                                                   add_92[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "average_pooling2d_14 (AveragePoo (None, 1, 1, 128)     0           add_93[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)             (None, 1, 1, 128)     0           average_pooling2d_14[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "flatten_14 (Flatten)             (None, 128)           0           dropout_14[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "dense_14 (Dense)                 (None, 7)             903         flatten_14[0][0]                 \n",
      "====================================================================================================\n",
      "Total params: 1,406,471\n",
      "Trainable params: 1,406,471\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "Non - Training\n",
      "('Train loss:', 1.9464396957760008)\n",
      "('Train accuracy:', 0.015430701173847922)\n",
      "Train on 28709 samples, validate on 3589 samples\n",
      "Epoch 1/20\n",
      "28709/28709 [==============================] - 21s - loss: 13.3771 - acc: 0.1691 - top_k_categorical_accuracy: 0.9995 - val_loss: 13.1855 - val_acc: 0.1819 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 2/20\n",
      " 5120/28709 [====>.........................] - ETA: 14s - loss: 12.8367 - acc: 0.2035 - top_k_categorical_accuracy: 1.0000"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "    #x_train, y_train, x_test, y_test, x_vali, y_vali = ReadData_fer()\n",
    "    \n",
    "    x_train = scipy.io.loadmat('/train/execute/fer2013/x_train.mat')['x_train']\n",
    "    x_test = scipy.io.loadmat('/train/execute/fer2013/x_test.mat')['x_test']\n",
    "    x_vali = scipy.io.loadmat('/train/execute/fer2013/x_vali.mat')['x_vali']\n",
    "    y_train = np.loadtxt('/train/execute/fer2013/y_train.txt')\n",
    "    y_test = np.loadtxt('/train/execute/fer2013/y_test.txt')\n",
    "    y_vali = np.loadtxt('/train/execute/fer2013/y_vali.txt')\n",
    "    # Normalization\n",
    "    #x_train = normalization(x_train)\n",
    "    #x_test = normalization(x_test)\n",
    "    #x_vali = normalization(x_vali)\n",
    "\n",
    "    x_train = x_train.reshape((len(x_train), 48, 48, 1))\n",
    "    x_test = x_test.reshape((len(x_test), 48, 48, 1))\n",
    "    x_vali = x_vali.reshape((len(x_vali),48,48,1))\n",
    "    \n",
    "    x_train /= 255\n",
    "    x_test /= 255\n",
    "    x_vali /= 255\n",
    "    print(x_train.shape)\n",
    "    print(x_test.shape)\n",
    "\n",
    "    model = check_print()\n",
    "    model.summary()\n",
    "    \n",
    "    score = model.evaluate(x_train,to_categorical(y_train),verbose=0)\n",
    "    print(\"Non - Training\")\n",
    "    print('Train loss:', score[0])\n",
    "    print('Train accuracy:', score[1])\n",
    "    \n",
    "    results = []\n",
    "    start_time = time.time()\n",
    "    history = model.fit(x_train,to_categorical(y_train),\n",
    "              epochs=EPOCH,\n",
    "              verbose=1,\n",
    "              validation_data=(x_vali, to_categorical(y_vali))\n",
    "    )\n",
    "    average_time_per_epoch = (time.time() - start_time) / EPOCH\n",
    "    results.append((history, average_time_per_epoch))\n",
    "    plt.style.use('ggplot')\n",
    "    ax1 = plt.subplot2grid((2, 2), (0, 0))\n",
    "    ax1.set_title('Accuracy')\n",
    "    ax1.set_ylabel('Accuracy')\n",
    "    ax1.set_xlabel('Epochs')\n",
    "    ax2 = plt.subplot2grid((2, 2), (1, 0))\n",
    "    ax2.set_title('Loss')\n",
    "    ax2.set_ylabel('Loss')\n",
    "    ax2.set_xlabel('Epochs')\n",
    "    ax3 = plt.subplot2grid((2, 2), (0, 1), rowspan=2)\n",
    "    ax3.set_title('Time')\n",
    "    ax3.set_ylabel('Seconds')\n",
    "    \n",
    "    for result in results:\n",
    "        ax1.plot(result[0].epoch, result[0].history['val_acc'], label='Vali')\n",
    "        ax1.plot(result[0].epoch, result[0].history['acc'], label='Train')\n",
    "        ax2.plot(result[0].epoch, result[0].history['val_loss'], label='Vali')\n",
    "        ax2.plot(result[0].epoch, result[0].history['loss'], label='Train')\n",
    "\n",
    "    ax1.legend()\n",
    "    ax2.legend()\n",
    "    ax3.bar(np.arange(len(results)), [x[1] for x in results],\n",
    "            align='center')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    score = model.evaluate(x_test, to_categorical(y_test), verbose=0)\n",
    "    print('Test loss:', score[0])\n",
    "    print('Test accuracy:', score[1])\n",
    "    \n",
    "    # model.fit_generator(train_generator,validation_data=vaild_generator,epochs=EPOCH,steps_per_epoch=train_generator.n/batch_size\n",
    "    #                     ,validation_steps=vaild_generator.n/batch_size)\n",
    "    # model.save('resnet_50.h5')\n",
    "    # loss,acc,top_acc=model.evaluate_generator(test_generator, steps=test_generator.n / batch_size)\n",
    "    # print('Test result:loss:%f,acc:%f,top_acc:%f' % (loss, acc, top_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
