{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## First Part: Load the data: \n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "def shuffle(x_,y_):\n",
    "    s = np.arange(x_.shape[0])\n",
    "    s = np.random.shuffle(s)\n",
    "\n",
    "    x_re = x_[s]\n",
    "    y_re = y_[s]\n",
    "\n",
    "    x_re = np.reshape(x_re,(len(x_),48,48))\n",
    "    y_re = np.reshape(y_re,(len(y_)))\n",
    "    return x_re,y_re\n",
    "\n",
    "def read_fer(path):\n",
    "    # train_path = \"C:\\\\Users\\\\Jiaming Nie\\\\Documents\\\\Work-DeepGlint\\Facial\\datasets\\\\train.csv\"\n",
    "    data = pd.read_csv(path, dtype='a')\n",
    "    label = np.array(data['emotion'])\n",
    "    img_data = np.array(data['pixels'])\n",
    "\n",
    "    N_sample = label.size\n",
    "\n",
    "    x_data = np.zeros((N_sample, 48 * 48))\n",
    "    # train_label = np.zeros((N_sample, 7), dtype=int)\n",
    "    y_label = np.zeros(N_sample, dtype=int)\n",
    "    # print(train_label)\n",
    "\n",
    "    for i in range(N_sample):\n",
    "        x = img_data[i]\n",
    "        x = np.fromstring(x, dtype=float, sep=' ')\n",
    "        x_max = x.max()\n",
    "        x = x / (x_max + 0.0001)\n",
    "        # print x_max\n",
    "        # print x\n",
    "        x_data[i] = x\n",
    "        y_label[i] = int(label[i])\n",
    "        # train_label[i, label[i]] = 1 #This step seems direct one-hot encoding\n",
    "        # print(y_label[i])\n",
    "        #    img_x = np.reshape(x, (48, 48))\n",
    "        #    plt.subplot(10,10,i+1)\n",
    "        #    plt.axis('off')\n",
    "        #    plt.imshow(img_x, plt.cm.gray)\n",
    "\n",
    "    x_data = np.reshape(x_data,(len(x_data),48,48))\n",
    "    return x_data, y_label\n",
    "\n",
    "def ReadData_fer():\n",
    "    # ubuntu path\n",
    "    #path_train = \"/home/jiaming/code/DeepGlint-Work/Facial/datasets/train.csv\"\n",
    "    #path_test = \"/home/jiaming/code/DeepGlint-Work/Facial/datasets/test.csv\"\n",
    "\n",
    "    # windows path\n",
    "    path_train = \"/train/trainset/1/train.csv\"\n",
    "    path_test = \"/train/trainset/1/test.csv\"\n",
    "    path_vali = \"/train/trainset/1/val.csv\"\n",
    "    \n",
    "    x_train, y_train = read_fer(path_train)\n",
    "    x_test, y_test = read_fer(path_test)\n",
    "    x_vali, y_vali = read_fer(path_vali)\n",
    "\n",
    "    x_train, y_train = shuffle(x_train, y_train)\n",
    "    x_test, y_test = shuffle(x_test, y_test)\n",
    "    x_vali, y_vali = shuffle(x_vali, y_vali)\n",
    "\n",
    "    return x_train,y_train,x_test,y_test,x_vali,y_vali\n",
    "\n",
    "def zca_whitening(X):\n",
    "    \"\"\"\n",
    "        Function to compute ZCA whitening matrix (aka Mahalanobis whitening).\n",
    "        INPUT:  X: [M x N] matrix.\n",
    "            Rows: Variables\n",
    "            Columns: Observations\n",
    "        OUTPUT: ZCAMatrix: [M x M] matrix\n",
    "        \"\"\"\n",
    "    mean_ = np.mean(X)\n",
    "    X = X - mean_\n",
    "    # Covariance matrix [column-wise variables]: Sigma = (X-mu)' * (X-mu) / N\n",
    "    sigma = np.cov(X, rowvar=True)  # [M x M]\n",
    "    # Singular Value Decomposition. X = U * np.diag(S) * V\n",
    "    U, S, V = np.linalg.svd(sigma)\n",
    "    # U: [M x M] eigenvectors of sigma.\n",
    "    # S: [M x 1] eigenvalues of sigma.\n",
    "    # V: [M x M] transpose of U\n",
    "    # Whitening constant: prevents division by zero\n",
    "    epsilon = 0.1\n",
    "    # ZCA Whitening matrix: U * Lambda * U'\n",
    "    ZCAMatrix = np.dot(U, np.dot(np.diag(1.0 / np.sqrt(S + epsilon)), U.T))  # [M x M]\n",
    "    return ZCAMatrix\n",
    "\n",
    "def normalization(x_):\n",
    "\n",
    "    length = len(x_)\n",
    "\n",
    "    for i in range(length):\n",
    "        x_[i] = zca_whitening(x_[i])\n",
    "\n",
    "    return x_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28709, 48, 48, 1)\n",
      "(3589, 48, 48, 1)\n"
     ]
    }
   ],
   "source": [
    "x_train,y_train,x_test,y_test,x_vali,y_vali = ReadData_fer()\n",
    "\n",
    "# Normalization\n",
    "x_train = normalization(x_train)\n",
    "x_test = normalization(x_test)\n",
    "x_vali = normalization(x_vali)\n",
    "\n",
    "x_train = x_train.reshape((len(x_train), 48, 48, 1))\n",
    "x_test = x_test.reshape((len(x_test), 48, 48, 1))\n",
    "x_vali = x_vali.reshape((len(x_vali),48,48,1))\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.misc import imread, imresize\n",
    "import keras\n",
    "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, AveragePooling2D, Dropout\n",
    "from keras.models import Model\n",
    "from keras.regularizers import l2\n",
    "from keras.optimizers import SGD\n",
    "import sys\n",
    "from keras.layers import Input, Dense, Conv2D, MaxPooling2D\n",
    "from keras.models import Model\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.regularizers import l2\n",
    "from keras.metrics import top_k_categorical_accuracy\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Flatten\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from keras import optimizers\n",
    "\n",
    "import tensorflow as tf\n",
    "gpu_options = tf.GPUOptions(allow_growth=True)\n",
    "sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))\n",
    "\n",
    "# 設定 Keras 使用的 Session\n",
    "tf.keras.backend.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def inception_model(input, filters_1x1, filters_3x3_reduce, filters_3x3, filters_5x5_reduce, filters_5x5, filters_pool_proj):\n",
    "    conv_1x1 = Conv2D(filters=filters_1x1, kernel_size=(1, 1), padding='same', activation='relu', kernel_regularizer=l2(0.01))(input)\n",
    "\n",
    "    conv_3x3_reduce = Conv2D(filters=filters_3x3_reduce, kernel_size=(1, 1), padding='same', activation='relu', kernel_regularizer=l2(0.01))(input)\n",
    "\n",
    "    conv_3x3 = Conv2D(filters=filters_3x3, kernel_size=(3, 3), padding='same', activation='relu', kernel_regularizer=l2(0.01))(conv_3x3_reduce)\n",
    "\n",
    "    conv_5x5_reduce  = Conv2D(filters=filters_5x5_reduce, kernel_size=(1, 1), padding='same', activation='relu', kernel_regularizer=l2(0.01))(input)\n",
    "\n",
    "    conv_5x5 = Conv2D(filters=filters_5x5, kernel_size=(5, 5), padding='same', activation='relu', kernel_regularizer=l2(0.01))(conv_5x5_reduce)\n",
    "\n",
    "    maxpool = MaxPooling2D(pool_size=(3, 3), strides=(1, 1), padding='same')(input)\n",
    "\n",
    "    maxpool_proj = Conv2D(filters=filters_pool_proj, kernel_size=(1, 1), strides=(1, 1), padding='same', activation='relu', kernel_regularizer=l2(0.01))(maxpool)\n",
    "\n",
    "    inception_output = concatenate([conv_1x1, conv_3x3, conv_5x5, maxpool_proj], axis=3)  # use tf as backend\n",
    "\n",
    "    return inception_output\n",
    "\n",
    "def define_model(weight_path = None):\n",
    "    input = Input(shape=(48, 48, 1))\n",
    "\n",
    "    conv1_7x7_s2 = Conv2D(filters=64, kernel_size=(7, 7), strides=(2, 2), padding='same', activation='relu', kernel_regularizer=l2(0.01))(input)\n",
    "\n",
    "    maxpool1_3x3_s2 = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding='same')(conv1_7x7_s2)\n",
    "\n",
    "    conv2_3x3_reduce = Conv2D(filters=64, kernel_size=(1, 1), padding='same', activation='relu', kernel_regularizer=l2(0.01))(maxpool1_3x3_s2)\n",
    "\n",
    "    conv2_3x3 = Conv2D(filters=192, kernel_size=(3, 3), padding='same', activation='relu', kernel_regularizer=l2(0.01))(conv2_3x3_reduce)\n",
    "\n",
    "    maxpool2_3x3_s2 = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding='same')(conv2_3x3)\n",
    "\n",
    "    inception_3a = inception_model(input=maxpool2_3x3_s2, filters_1x1=64, filters_3x3_reduce=96, filters_3x3=128, filters_5x5_reduce=16, filters_5x5=32, filters_pool_proj=32)\n",
    "\n",
    "    inception_3b = inception_model(input=inception_3a, filters_1x1=128, filters_3x3_reduce=128, filters_3x3=192, filters_5x5_reduce=32, filters_5x5=96, filters_pool_proj=64)\n",
    "\n",
    "    maxpool3_3x3_s2 = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding='same')(inception_3b)\n",
    "\n",
    "    inception_4a = inception_model(input=maxpool3_3x3_s2, filters_1x1=192, filters_3x3_reduce=96, filters_3x3=208, filters_5x5_reduce=16, filters_5x5=48, filters_pool_proj=64)\n",
    "\n",
    "    inception_4b = inception_model(input=inception_4a, filters_1x1=160, filters_3x3_reduce=112, filters_3x3=224, filters_5x5_reduce=24, filters_5x5=64, filters_pool_proj=64)\n",
    "\n",
    "    inception_4c = inception_model(input=inception_4b, filters_1x1=128, filters_3x3_reduce=128, filters_3x3=256, filters_5x5_reduce=24, filters_5x5=64, filters_pool_proj=64)\n",
    "\n",
    "    inception_4d = inception_model(input=inception_4c, filters_1x1=112, filters_3x3_reduce=144, filters_3x3=288, filters_5x5_reduce=32, filters_5x5=64, filters_pool_proj=64)\n",
    "\n",
    "    inception_4e = inception_model(input=inception_4d, filters_1x1=256, filters_3x3_reduce=160, filters_3x3=320, filters_5x5_reduce=32, filters_5x5=128, filters_pool_proj=128)\n",
    "\n",
    "    maxpool4_3x3_s2 = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding='same')(inception_4e)\n",
    "\n",
    "    inception_5a = inception_model(input=maxpool4_3x3_s2, filters_1x1=256, filters_3x3_reduce=160, filters_3x3=320, filters_5x5_reduce=32, filters_5x5=128, filters_pool_proj=128)\n",
    "\n",
    "    inception_5b = inception_model(input=inception_5a, filters_1x1=384, filters_3x3_reduce=192, filters_3x3=384, filters_5x5_reduce=48, filters_5x5=128, filters_pool_proj=128)\n",
    "\n",
    "    averagepool1_7x7_s1 = AveragePooling2D(pool_size=(7, 7), strides=(7, 7), padding='same')(inception_5b)\n",
    "\n",
    "    drop1 = Dropout(rate=0.4)(averagepool1_7x7_s1)\n",
    "    #print(drop1)\n",
    "\n",
    "    #flatten = keras.layers.core.Flatten(drop1)\n",
    "    #print(\"flatten \",flatten)\n",
    "\n",
    "    #linear = Dense(units=7, activation='softmax', kernel_regularizer=l2(0.01))(keras.layers.core.Flatten(drop1))\n",
    "    drop1 = Flatten()(drop1)\n",
    "    linear = Dense(units=7, activation='softmax', kernel_regularizer=l2(0.01))(drop1)\n",
    "    last = linear\n",
    "\n",
    "    model = Model(inputs=input, outputs=last)\n",
    "    #model.summary()\n",
    "    sgd = optimizers.SGD(lr=0.0001, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    model.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    batch_size = 16\n",
    "    EPOCH = 100\n",
    "    \n",
    "    results = []\n",
    "    start_time = time.time()\n",
    "\n",
    "    history = model.fit(x_train, to_categorical(y_train),\n",
    "              batch_size=batch_size,\n",
    "              epochs=EPOCH,\n",
    "              validation_data=(x_vali, to_categorical(y_vali)))\n",
    "\n",
    "    average_time_per_epoch = (time.time() - start_time) / EPOCH\n",
    "    results.append((history, average_time_per_epoch))\n",
    "    plt.style.use('ggplot')\n",
    "    ax1 = plt.subplot2grid((2, 2), (0, 0))\n",
    "    ax1.set_title('Accuracy')\n",
    "    ax1.set_ylabel('Accuracy')\n",
    "    ax1.set_xlabel('Epochs')\n",
    "    ax2 = plt.subplot2grid((2, 2), (1, 0))\n",
    "    ax2.set_title('Loss')\n",
    "    ax2.set_ylabel('Loss')\n",
    "    ax2.set_xlabel('Epochs')\n",
    "    ax3 = plt.subplot2grid((2, 2), (0, 1), rowspan=2)\n",
    "    ax3.set_title('Time')\n",
    "    ax3.set_ylabel('Seconds')\n",
    "\n",
    "    for result in results:\n",
    "        ax1.plot(result[0].epoch, result[0].history['val_acc'], label='Test')\n",
    "        ax1.plot(result[0].epoch, result[0].history['acc'], label='Train')\n",
    "        ax2.plot(result[0].epoch, result[0].history['val_loss'], label='Test')\n",
    "        ax2.plot(result[0].epoch, result[0].history['loss'], label='Train')\n",
    "\n",
    "    ax1.legend()\n",
    "    ax2.legend()\n",
    "    ax3.bar(np.arange(len(results)), [x[1] for x in results],\n",
    "            align='center')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    score = model.evaluate(x_test, to_categorical(y_test), verbose=0)\n",
    "    print('Test loss:', score[0])\n",
    "    print('Test accuracy:', score[1])\n",
    "\n",
    "    #return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Variable *= will be deprecated. Use variable.assign_mul if you want assignment to the variable value or 'x = x * y' if you want a new python Tensor object.\n",
      "Train on 28709 samples, validate on 3589 samples\n",
      "Epoch 1/100\n",
      "28709/28709 [==============================] - 186s 6ms/step - loss: 81.2457 - acc: 0.2492 - val_loss: 78.3993 - val_acc: 0.2494\n",
      "Epoch 2/100\n",
      "28709/28709 [==============================] - 176s 6ms/step - loss: 75.7095 - acc: 0.2513 - val_loss: 73.0855 - val_acc: 0.2494\n",
      "Epoch 3/100\n",
      "28709/28709 [==============================] - 180s 6ms/step - loss: 70.5964 - acc: 0.2513 - val_loss: 68.1647 - val_acc: 0.2494\n",
      "Epoch 4/100\n",
      "28709/28709 [==============================] - 180s 6ms/step - loss: 65.8541 - acc: 0.2513 - val_loss: 63.5958 - val_acc: 0.2494\n",
      "Epoch 5/100\n",
      "28709/28709 [==============================] - 179s 6ms/step - loss: 61.4489 - acc: 0.2513 - val_loss: 59.3500 - val_acc: 0.2494\n",
      "Epoch 6/100\n",
      "28709/28709 [==============================] - 179s 6ms/step - loss: 57.3541 - acc: 0.2513 - val_loss: 55.4031 - val_acc: 0.2494\n",
      "Epoch 7/100\n",
      "28709/28709 [==============================] - 181s 6ms/step - loss: 53.5474 - acc: 0.2513 - val_loss: 51.7336 - val_acc: 0.2494\n",
      "Epoch 8/100\n",
      "28709/28709 [==============================] - 178s 6ms/step - loss: 50.0079 - acc: 0.2513 - val_loss: 48.3210 - val_acc: 0.2494\n",
      "Epoch 9/100\n",
      "28709/28709 [==============================] - 179s 6ms/step - loss: 46.7156 - acc: 0.2513 - val_loss: 45.1470 - val_acc: 0.2494\n",
      "Epoch 10/100\n",
      "28709/28709 [==============================] - 182s 6ms/step - loss: 43.6537 - acc: 0.2513 - val_loss: 42.1945 - val_acc: 0.2494\n",
      "Epoch 11/100\n",
      "28709/28709 [==============================] - 180s 6ms/step - loss: 40.8052 - acc: 0.2513 - val_loss: 39.4477 - val_acc: 0.2494\n",
      "Epoch 12/100\n",
      "28709/28709 [==============================] - 179s 6ms/step - loss: 38.1550 - acc: 0.2513 - val_loss: 36.8922 - val_acc: 0.2494\n",
      "Epoch 13/100\n",
      "28709/28709 [==============================] - 180s 6ms/step - loss: 35.6891 - acc: 0.2513 - val_loss: 34.5141 - val_acc: 0.2494\n",
      "Epoch 14/100\n",
      "28709/28709 [==============================] - 181s 6ms/step - loss: 33.3945 - acc: 0.2513 - val_loss: 32.3009 - val_acc: 0.2494\n",
      "Epoch 15/100\n",
      "28709/28709 [==============================] - 180s 6ms/step - loss: 31.2590 - acc: 0.2513 - val_loss: 30.2410 - val_acc: 0.2494\n",
      "Epoch 16/100\n",
      "28709/28709 [==============================] - 175s 6ms/step - loss: 29.2707 - acc: 0.2513 - val_loss: 28.3234 - val_acc: 0.2494\n",
      "Epoch 17/100\n",
      "28709/28709 [==============================] - 181s 6ms/step - loss: 27.4199 - acc: 0.2513 - val_loss: 26.5382 - val_acc: 0.2494\n",
      "Epoch 18/100\n",
      "28709/28709 [==============================] - 183s 6ms/step - loss: 25.6968 - acc: 0.2513 - val_loss: 24.8760 - val_acc: 0.2494\n",
      "Epoch 19/100\n",
      "28709/28709 [==============================] - 178s 6ms/step - loss: 24.0924 - acc: 0.2513 - val_loss: 23.3282 - val_acc: 0.2494\n",
      "Epoch 20/100\n",
      "28709/28709 [==============================] - 180s 6ms/step - loss: 22.5984 - acc: 0.2513 - val_loss: 21.8867 - val_acc: 0.2494\n",
      "Epoch 21/100\n",
      "28709/28709 [==============================] - 182s 6ms/step - loss: 21.2071 - acc: 0.2513 - val_loss: 20.5441 - val_acc: 0.2494\n",
      "Epoch 22/100\n",
      "28709/28709 [==============================] - 180s 6ms/step - loss: 19.9109 - acc: 0.2513 - val_loss: 19.2932 - val_acc: 0.2494\n",
      "Epoch 23/100\n",
      "28709/28709 [==============================] - 182s 6ms/step - loss: 18.7032 - acc: 0.2513 - val_loss: 18.1279 - val_acc: 0.2494\n",
      "Epoch 24/100\n",
      "28709/28709 [==============================] - 182s 6ms/step - loss: 17.5782 - acc: 0.2513 - val_loss: 17.0422 - val_acc: 0.2494\n",
      "Epoch 25/100\n",
      "28709/28709 [==============================] - 180s 6ms/step - loss: 16.5298 - acc: 0.2513 - val_loss: 16.0303 - val_acc: 0.2494\n",
      "Epoch 26/100\n",
      "28709/28709 [==============================] - 183s 6ms/step - loss: 15.5529 - acc: 0.2513 - val_loss: 15.0872 - val_acc: 0.2494\n",
      "Epoch 27/100\n",
      "28709/28709 [==============================] - 184s 6ms/step - loss: 14.6419 - acc: 0.2513 - val_loss: 14.2082 - val_acc: 0.2494\n",
      "Epoch 28/100\n",
      "28709/28709 [==============================] - 185s 6ms/step - loss: 13.7931 - acc: 0.2513 - val_loss: 13.3888 - val_acc: 0.2494\n",
      "Epoch 29/100\n",
      "28709/28709 [==============================] - 185s 6ms/step - loss: 13.0014 - acc: 0.2513 - val_loss: 12.6248 - val_acc: 0.2494\n",
      "Epoch 30/100\n",
      "28709/28709 [==============================] - 178s 6ms/step - loss: 12.2636 - acc: 0.2513 - val_loss: 11.9124 - val_acc: 0.2494\n",
      "Epoch 31/100\n",
      "28709/28709 [==============================] - 183s 6ms/step - loss: 11.5755 - acc: 0.2513 - val_loss: 11.2480 - val_acc: 0.2494\n",
      "Epoch 32/100\n",
      "28709/28709 [==============================] - 183s 6ms/step - loss: 10.9338 - acc: 0.2513 - val_loss: 10.6284 - val_acc: 0.2494\n",
      "Epoch 33/100\n",
      "28709/28709 [==============================] - 183s 6ms/step - loss: 10.3349 - acc: 0.2513 - val_loss: 10.0504 - val_acc: 0.2494\n",
      "Epoch 34/100\n",
      "28709/28709 [==============================] - 182s 6ms/step - loss: 9.7766 - acc: 0.2513 - val_loss: 9.5111 - val_acc: 0.2494\n",
      "Epoch 35/100\n",
      "28709/28709 [==============================] - 184s 6ms/step - loss: 9.2558 - acc: 0.2513 - val_loss: 9.0081 - val_acc: 0.2494\n",
      "Epoch 36/100\n",
      "28709/28709 [==============================] - 183s 6ms/step - loss: 8.7699 - acc: 0.2513 - val_loss: 8.5388 - val_acc: 0.2494\n",
      "Epoch 37/100\n",
      "28709/28709 [==============================] - 184s 6ms/step - loss: 8.3163 - acc: 0.2513 - val_loss: 8.1007 - val_acc: 0.2494\n",
      "Epoch 38/100\n",
      "28709/28709 [==============================] - 184s 6ms/step - loss: 7.8929 - acc: 0.2513 - val_loss: 7.6918 - val_acc: 0.2494\n",
      "Epoch 39/100\n",
      "28709/28709 [==============================] - 184s 6ms/step - loss: 7.4975 - acc: 0.2513 - val_loss: 7.3101 - val_acc: 0.2494\n",
      "Epoch 40/100\n",
      "28709/28709 [==============================] - 186s 6ms/step - loss: 7.1286 - acc: 0.2513 - val_loss: 6.9538 - val_acc: 0.2494\n",
      "Epoch 41/100\n",
      "28709/28709 [==============================] - 183s 6ms/step - loss: 6.7845 - acc: 0.2513 - val_loss: 6.6211 - val_acc: 0.2494\n",
      "Epoch 42/100\n",
      "28709/28709 [==============================] - 185s 6ms/step - loss: 6.4629 - acc: 0.2513 - val_loss: 6.3105 - val_acc: 0.2494\n",
      "Epoch 43/100\n",
      "28709/28709 [==============================] - 186s 6ms/step - loss: 6.1628 - acc: 0.2513 - val_loss: 6.0204 - val_acc: 0.2494\n",
      "Epoch 44/100\n",
      "28709/28709 [==============================] - 178s 6ms/step - loss: 5.8823 - acc: 0.2513 - val_loss: 5.7495 - val_acc: 0.2494\n",
      "Epoch 45/100\n",
      "28709/28709 [==============================] - 185s 6ms/step - loss: 5.6203 - acc: 0.2513 - val_loss: 5.4964 - val_acc: 0.2494\n",
      "Epoch 46/100\n",
      "28709/28709 [==============================] - 182s 6ms/step - loss: 5.3755 - acc: 0.2513 - val_loss: 5.2599 - val_acc: 0.2494\n",
      "Epoch 47/100\n",
      "28709/28709 [==============================] - 186s 6ms/step - loss: 5.1470 - acc: 0.2513 - val_loss: 5.0390 - val_acc: 0.2494\n",
      "Epoch 48/100\n",
      "28709/28709 [==============================] - 185s 6ms/step - loss: 4.9336 - acc: 0.2513 - val_loss: 4.8326 - val_acc: 0.2494\n",
      "Epoch 49/100\n",
      "28709/28709 [==============================] - 184s 6ms/step - loss: 4.7338 - acc: 0.2513 - val_loss: 4.6398 - val_acc: 0.2494\n",
      "Epoch 50/100\n",
      "28709/28709 [==============================] - 186s 6ms/step - loss: 4.5473 - acc: 0.2513 - val_loss: 4.4595 - val_acc: 0.2494\n",
      "Epoch 51/100\n",
      "28709/28709 [==============================] - 184s 6ms/step - loss: 4.3730 - acc: 0.2513 - val_loss: 4.2910 - val_acc: 0.2494\n",
      "Epoch 52/100\n",
      "28709/28709 [==============================] - 184s 6ms/step - loss: 4.2102 - acc: 0.2513 - val_loss: 4.1334 - val_acc: 0.2494\n",
      "Epoch 53/100\n",
      "28709/28709 [==============================] - 185s 6ms/step - loss: 4.0577 - acc: 0.2513 - val_loss: 3.9861 - val_acc: 0.2494\n",
      "Epoch 54/100\n",
      "28709/28709 [==============================] - 184s 6ms/step - loss: 3.9152 - acc: 0.2513 - val_loss: 3.8484 - val_acc: 0.2494\n",
      "Epoch 55/100\n",
      "28709/28709 [==============================] - 185s 6ms/step - loss: 3.7820 - acc: 0.2513 - val_loss: 3.7197 - val_acc: 0.2494\n",
      "Epoch 56/100\n",
      "28709/28709 [==============================] - 184s 6ms/step - loss: 3.6576 - acc: 0.2513 - val_loss: 3.5993 - val_acc: 0.2494\n",
      "Epoch 57/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28709/28709 [==============================] - 183s 6ms/step - loss: 3.5410 - acc: 0.2513 - val_loss: 3.4866 - val_acc: 0.2494\n",
      "Epoch 58/100\n",
      "28709/28709 [==============================] - 179s 6ms/step - loss: 3.4321 - acc: 0.2513 - val_loss: 3.3812 - val_acc: 0.2494\n",
      "Epoch 59/100\n",
      "28709/28709 [==============================] - 184s 6ms/step - loss: 3.3300 - acc: 0.2513 - val_loss: 3.2826 - val_acc: 0.2494\n",
      "Epoch 60/100\n",
      "28709/28709 [==============================] - 183s 6ms/step - loss: 3.2347 - acc: 0.2513 - val_loss: 3.1904 - val_acc: 0.2494\n",
      "Epoch 61/100\n",
      "28709/28709 [==============================] - 184s 6ms/step - loss: 3.1453 - acc: 0.2513 - val_loss: 3.1040 - val_acc: 0.2494\n",
      "Epoch 62/100\n",
      "28709/28709 [==============================] - 185s 6ms/step - loss: 3.0620 - acc: 0.2513 - val_loss: 3.0233 - val_acc: 0.2494\n",
      "Epoch 63/100\n",
      "28709/28709 [==============================] - 185s 6ms/step - loss: 2.9836 - acc: 0.2513 - val_loss: 2.9477 - val_acc: 0.2494\n",
      "Epoch 64/100\n",
      "28709/28709 [==============================] - 185s 6ms/step - loss: 2.9105 - acc: 0.2513 - val_loss: 2.8769 - val_acc: 0.2494\n",
      "Epoch 65/100\n",
      "28709/28709 [==============================] - 184s 6ms/step - loss: 2.8420 - acc: 0.2513 - val_loss: 2.8106 - val_acc: 0.2494\n",
      "Epoch 66/100\n",
      "28709/28709 [==============================] - 184s 6ms/step - loss: 2.7779 - acc: 0.2513 - val_loss: 2.7486 - val_acc: 0.2494\n",
      "Epoch 67/100\n",
      "28709/28709 [==============================] - 183s 6ms/step - loss: 2.7179 - acc: 0.2513 - val_loss: 2.6904 - val_acc: 0.2494\n",
      "Epoch 68/100\n",
      "28709/28709 [==============================] - 184s 6ms/step - loss: 2.6616 - acc: 0.2513 - val_loss: 2.6361 - val_acc: 0.2494\n",
      "Epoch 69/100\n",
      "28709/28709 [==============================] - 187s 6ms/step - loss: 2.6090 - acc: 0.2513 - val_loss: 2.5851 - val_acc: 0.2494\n",
      "Epoch 70/100\n",
      "28709/28709 [==============================] - 183s 6ms/step - loss: 2.5596 - acc: 0.2513 - val_loss: 2.5374 - val_acc: 0.2494\n",
      "Epoch 71/100\n",
      "28709/28709 [==============================] - 176s 6ms/step - loss: 2.5134 - acc: 0.2513 - val_loss: 2.4927 - val_acc: 0.2494\n",
      "Epoch 72/100\n",
      "28709/28709 [==============================] - 173s 6ms/step - loss: 2.4702 - acc: 0.2513 - val_loss: 2.4508 - val_acc: 0.2494\n",
      "Epoch 73/100\n",
      "28709/28709 [==============================] - 179s 6ms/step - loss: 2.4296 - acc: 0.2513 - val_loss: 2.4116 - val_acc: 0.2494\n",
      "Epoch 74/100\n",
      "28709/28709 [==============================] - 179s 6ms/step - loss: 2.3916 - acc: 0.2513 - val_loss: 2.3748 - val_acc: 0.2494\n",
      "Epoch 75/100\n",
      "28709/28709 [==============================] - 177s 6ms/step - loss: 2.3560 - acc: 0.2513 - val_loss: 2.3403 - val_acc: 0.2494\n",
      "Epoch 76/100\n",
      "28709/28709 [==============================] - 177s 6ms/step - loss: 2.3226 - acc: 0.2513 - val_loss: 2.3081 - val_acc: 0.2494\n",
      "Epoch 77/100\n",
      "28709/28709 [==============================] - 177s 6ms/step - loss: 2.2913 - acc: 0.2513 - val_loss: 2.2778 - val_acc: 0.2494\n",
      "Epoch 78/100\n",
      "28709/28709 [==============================] - 176s 6ms/step - loss: 2.2621 - acc: 0.2513 - val_loss: 2.2494 - val_acc: 0.2494\n",
      "Epoch 79/100\n",
      "28709/28709 [==============================] - 176s 6ms/step - loss: 2.2345 - acc: 0.2513 - val_loss: 2.2228 - val_acc: 0.2494\n",
      "Epoch 80/100\n",
      "28709/28709 [==============================] - 178s 6ms/step - loss: 2.2087 - acc: 0.2513 - val_loss: 2.1978 - val_acc: 0.2494\n",
      "Epoch 81/100\n",
      "28709/28709 [==============================] - 176s 6ms/step - loss: 2.1846 - acc: 0.2513 - val_loss: 2.1744 - val_acc: 0.2494\n",
      "Epoch 82/100\n",
      "28709/28709 [==============================] - 179s 6ms/step - loss: 2.1619 - acc: 0.2513 - val_loss: 2.1525 - val_acc: 0.2494\n",
      "Epoch 83/100\n",
      "28709/28709 [==============================] - 178s 6ms/step - loss: 2.1406 - acc: 0.2513 - val_loss: 2.1319 - val_acc: 0.2494\n",
      "Epoch 84/100\n",
      "28709/28709 [==============================] - 179s 6ms/step - loss: 2.1207 - acc: 0.2513 - val_loss: 2.1126 - val_acc: 0.2494\n",
      "Epoch 85/100\n",
      "28709/28709 [==============================] - 177s 6ms/step - loss: 2.1021 - acc: 0.2513 - val_loss: 2.0944 - val_acc: 0.2494\n",
      "Epoch 86/100\n",
      "28709/28709 [==============================] - 170s 6ms/step - loss: 2.0845 - acc: 0.2513 - val_loss: 2.0775 - val_acc: 0.2494\n",
      "Epoch 87/100\n",
      "28709/28709 [==============================] - 178s 6ms/step - loss: 2.0679 - acc: 0.2513 - val_loss: 2.0615 - val_acc: 0.2494\n",
      "Epoch 88/100\n",
      "28709/28709 [==============================] - 177s 6ms/step - loss: 2.0525 - acc: 0.2513 - val_loss: 2.0466 - val_acc: 0.2494\n",
      "Epoch 89/100\n",
      "28709/28709 [==============================] - 175s 6ms/step - loss: 2.0381 - acc: 0.2513 - val_loss: 2.0325 - val_acc: 0.2494\n",
      "Epoch 90/100\n",
      "28709/28709 [==============================] - 175s 6ms/step - loss: 2.0244 - acc: 0.2513 - val_loss: 2.0193 - val_acc: 0.2494\n",
      "Epoch 91/100\n",
      "28709/28709 [==============================] - 176s 6ms/step - loss: 2.0117 - acc: 0.2513 - val_loss: 2.0069 - val_acc: 0.2494\n",
      "Epoch 92/100\n",
      "28709/28709 [==============================] - 178s 6ms/step - loss: 1.9996 - acc: 0.2513 - val_loss: 1.9953 - val_acc: 0.2494\n",
      "Epoch 93/100\n",
      "28709/28709 [==============================] - 176s 6ms/step - loss: 1.9884 - acc: 0.2513 - val_loss: 1.9844 - val_acc: 0.2494\n",
      "Epoch 94/100\n",
      "28709/28709 [==============================] - 177s 6ms/step - loss: 1.9778 - acc: 0.2513 - val_loss: 1.9742 - val_acc: 0.2494\n",
      "Epoch 95/100\n",
      "28709/28709 [==============================] - 176s 6ms/step - loss: 1.9678 - acc: 0.2513 - val_loss: 1.9645 - val_acc: 0.2494\n",
      "Epoch 96/100\n",
      "28709/28709 [==============================] - 177s 6ms/step - loss: 1.9585 - acc: 0.2513 - val_loss: 1.9554 - val_acc: 0.2494\n",
      "Epoch 97/100\n",
      "28709/28709 [==============================] - 175s 6ms/step - loss: 1.9497 - acc: 0.2513 - val_loss: 1.9470 - val_acc: 0.2494\n",
      "Epoch 98/100\n",
      "28709/28709 [==============================] - 176s 6ms/step - loss: 1.9415 - acc: 0.2513 - val_loss: 1.9390 - val_acc: 0.2494\n",
      "Epoch 99/100\n",
      "28709/28709 [==============================] - 172s 6ms/step - loss: 1.9338 - acc: 0.2513 - val_loss: 1.9315 - val_acc: 0.2494\n",
      "Epoch 100/100\n",
      "13568/28709 [=============>................] - ETA: 1:25 - loss: 1.9290 - acc: 0.2558"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-54c83ea4daea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefine_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-25-620e3d6dd4ae>\u001b[0m in \u001b[0;36mdefine_model\u001b[0;34m(weight_path)\u001b[0m\n\u001b[1;32m     81\u001b[0m               \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m               \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEPOCH\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m               validation_data=(x_vali, to_categorical(y_vali)))\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0maverage_time_per_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mEPOCH\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1703\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1704\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1705\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1234\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1236\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1237\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2480\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2481\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2482\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2483\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    898\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 900\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    901\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1135\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1136\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1316\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1317\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1320\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1324\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1305\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1307\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1407\u001b[0m       return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m           run_metadata)\n\u001b[0m\u001b[1;32m   1410\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    model = define_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
